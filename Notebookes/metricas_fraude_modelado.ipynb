{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3e4c8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Librer√≠as importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from river import anomaly\n",
    "from river import preprocessing\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6db7d6",
   "metadata": {},
   "source": [
    "# # 1. CONFIGURACI√ìN DE RUTAS Y CARGA DE MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4b986b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Directorio de modelos: C:\\Users\\User\\Desktop\\TESIS\\CodigoGithub\\MLTallerProyecto1\\Modelos\n"
     ]
    }
   ],
   "source": [
    "# Rutas de archivos\n",
    "MODELS_PATH = r\"C:\\Users\\User\\Desktop\\TESIS\\CodigoGithub\\MLTallerProyecto1\\Modelos\"\n",
    "EVALUATION_CSV_PATH = r\"C:\\Users\\User\\Desktop\\TESIS\\NuevoDataSet\\DataSetFinalProbarMatriz.csv\"  # üîß CAMBIAR ESTA RUTA\n",
    "RESULTADO = r\"C:\\Users\\User\\Desktop\\TESIS\\CodigoGithub\\MLTallerProyecto1\\Resultados\"\n",
    "\n",
    "# Verificar que el directorio de modelos existe\n",
    "if not os.path.exists(MODELS_PATH):\n",
    "    print(f\"‚ùå Error: Directorio de modelos no encontrado: {MODELS_PATH}\")\n",
    "    exit()\n",
    "\n",
    "print(f\"üìÅ Directorio de modelos: {MODELS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fbff4b",
   "metadata": {},
   "source": [
    "# 2. CARGAR MODELO, SCALER Y CONFIGURACI√ìN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9455c4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Cargando modelo entrenado...\n",
      "‚úÖ Modelo cargado exitosamente\n",
      "\n",
      "üìä INFORMACI√ìN DEL MODELO CARGADO:\n",
      "üéØ Umbral global: 0.9724\n",
      "üåç Pa√≠ses en entrenamiento: 188\n",
      "üìà Registros de entrenamiento: 450900\n",
      "üìÖ Fecha de entrenamiento: 2025-06-16T20:17:02.325706\n",
      "üå≥ N√∫mero de √°rboles: 80\n",
      "üìè Altura de √°rboles: 10\n",
      "\n",
      "‚öôÔ∏è PAR√ÅMETROS DE FEATURES CARGADOS:\n",
      "üîß Peso minutos normal: 0.4\n",
      "üîß Peso minutos extremos: 1.5\n",
      "üîß Umbral minutos extremos: 300\n",
      "üîß Peso destinos: 1.2\n",
      "üîß Peso spray ratio: 1.5\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîÑ Cargando modelo entrenado...\")\n",
    "\n",
    "# Cargar modelo\n",
    "modelo_path = os.path.join(MODELS_PATH, \"modelo_general.pkl\")\n",
    "with open(modelo_path, 'rb') as f:\n",
    "    modelo_cargado = pickle.load(f)\n",
    "\n",
    "# Cargar scaler\n",
    "scaler_path = os.path.join(MODELS_PATH, \"scaler_general.pkl\")\n",
    "with open(scaler_path, 'rb') as f:\n",
    "    scaler_cargado = pickle.load(f)\n",
    "\n",
    "# Cargar configuraci√≥n\n",
    "config_path = os.path.join(MODELS_PATH, \"config_modelo_general.pkl\")\n",
    "with open(config_path, 'rb') as f:\n",
    "    config_cargado = pickle.load(f)\n",
    "\n",
    "print(\"‚úÖ Modelo cargado exitosamente\")\n",
    "\n",
    "# Mostrar informaci√≥n del modelo\n",
    "print(f\"\\nüìä INFORMACI√ìN DEL MODELO CARGADO:\")\n",
    "print(f\"üéØ Umbral global: {config_cargado['umbral_global']:.4f}\")\n",
    "print(f\"üåç Pa√≠ses en entrenamiento: {config_cargado['paises_entrenamiento']}\")\n",
    "print(f\"üìà Registros de entrenamiento: {config_cargado['registros_entrenamiento']}\")\n",
    "print(f\"üìÖ Fecha de entrenamiento: {config_cargado['fecha_entrenamiento']}\")\n",
    "print(f\"üå≥ N√∫mero de √°rboles: {config_cargado['n_trees']}\")\n",
    "print(f\"üìè Altura de √°rboles: {config_cargado['tree_height']}\")\n",
    "\n",
    "# Extraer configuraciones\n",
    "umbral_global = config_cargado['umbral_global']\n",
    "stats_dict  = config_cargado['stats_por_pais']\n",
    "parametros_features = config_cargado['parametros_features']\n",
    "contexto_historico = config_cargado['contexto_historico']\n",
    "\n",
    "\n",
    "# Configurar par√°metros de features\n",
    "PESO_MINUTOS_NORMAL = parametros_features['peso_minutos_normal']\n",
    "PESO_MINUTOS_EXTREMOS = parametros_features['peso_minutos_extremos']\n",
    "UMBRAL_MINUTOS_EXTREMOS = parametros_features['umbral_minutos_extremos']\n",
    "PESO_DESTINOS = parametros_features['peso_destinos']\n",
    "PESO_SPRAY_RATIO = parametros_features['peso_spray_ratio']\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è PAR√ÅMETROS DE FEATURES CARGADOS:\")\n",
    "print(f\"üîß Peso minutos normal: {PESO_MINUTOS_NORMAL}\")\n",
    "print(f\"üîß Peso minutos extremos: {PESO_MINUTOS_EXTREMOS}\")\n",
    "print(f\"üîß Umbral minutos extremos: {UMBRAL_MINUTOS_EXTREMOS}\")\n",
    "print(f\"üîß Peso destinos: {PESO_DESTINOS}\")\n",
    "print(f\"üîß Peso spray ratio: {PESO_SPRAY_RATIO}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4284ae75",
   "metadata": {},
   "source": [
    "# # 3. FUNCI√ìN DE FEATURES (ID√âNTICA AL MODELO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d093435f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Funciones de predicci√≥n cargadas (id√©nticas al modelo)\n"
     ]
    }
   ],
   "source": [
    "def crear_features_contextualizadas_mejorada(row, stats_pais_dict):\n",
    "    \"\"\"\n",
    "    Funci√≥n id√©ntica a la del modelo - MANTENER CONSISTENCIA ABSOLUTA\n",
    "    \"\"\"\n",
    "    pais = row['CODIGODEPAIS']\n",
    "    llamadas = row['N_LLAMADAS']\n",
    "    minutos = row['N_MINUTOS']\n",
    "    destinos = row['N_DESTINOS']\n",
    "    \n",
    "    # Obtener contexto del pa√≠s (si existe)\n",
    "    if pais in stats_pais_dict:\n",
    "        pais_stats = stats_pais_dict[pais]\n",
    "        categoria = pais_stats['CATEGORIA']\n",
    "        \n",
    "        # Normalizar por el contexto del pa√≠s\n",
    "        llamadas_norm = min(llamadas / max(pais_stats['LLAMADAS_P95'], 1), 1.5)\n",
    "        destinos_norm = min(destinos / max(pais_stats['DESTINOS_P95'], 1), 1.5)\n",
    "        \n",
    "        # Detecci√≥n inteligente de minutos extremos\n",
    "        minutos_p90 = pais_stats.get('MINUTOS_P90', pais_stats['MINUTOS_P95'] * 0.9)\n",
    "        \n",
    "        # Transformaci√≥n adaptativa de minutos\n",
    "        if minutos >= UMBRAL_MINUTOS_EXTREMOS:\n",
    "            minutos_norm = min(minutos / max(minutos_p90, 1), 3.0)\n",
    "            peso_minutos = PESO_MINUTOS_EXTREMOS\n",
    "        else:\n",
    "            minutos_norm = min(np.log1p(minutos) / np.log1p(max(minutos_p90, 1)), 1.2)\n",
    "            peso_minutos = PESO_MINUTOS_NORMAL\n",
    "            \n",
    "    else:\n",
    "        # Pa√≠s nuevo - SIEMPRE clasificar como 'Muy_Bajo'\n",
    "        categoria = 'Muy_Bajo'\n",
    "        llamadas_norm = min(llamadas / 10, 2.0)\n",
    "        destinos_norm = min(destinos / 5, 2.0)\n",
    "        \n",
    "        if minutos >= UMBRAL_MINUTOS_EXTREMOS:\n",
    "            minutos_norm = min(minutos / 50, 3.0)\n",
    "            peso_minutos = PESO_MINUTOS_EXTREMOS * 1.2\n",
    "        else:\n",
    "            minutos_norm = min(np.log1p(minutos) / np.log1p(60), 1.2)\n",
    "            peso_minutos = PESO_MINUTOS_NORMAL\n",
    "    \n",
    "    # Features principales (id√©nticas al modelo)\n",
    "    features = {\n",
    "        'llamadas_norm': llamadas_norm * 0.8,\n",
    "        'destinos_norm': destinos_norm * PESO_DESTINOS,\n",
    "        'minutos_norm': minutos_norm * peso_minutos,\n",
    "        'diversidad_destinos': min(destinos / max(llamadas, 1), 1.0),\n",
    "        'spray_ratio': min(destinos / max(llamadas, 1) * PESO_SPRAY_RATIO, 1.0) if destinos >= 5 else 0,\n",
    "        'minutos_extremos': 1.0 if minutos >= UMBRAL_MINUTOS_EXTREMOS else 0.0,\n",
    "        'minutos_sospechosos': min((minutos - 200) / 300, 1.0) if minutos > 200 else 0.0,\n",
    "        'patron_spray_fuerte': 1.0 if (destinos >= 10 and llamadas >= 20) else 0.0,\n",
    "        'patron_spray_medio': 0.5 if (destinos >= 6 and llamadas >= 12) else 0.0,\n",
    "        'alta_diversidad': min(destinos / 12, 1) if destinos >= 5 else 0,\n",
    "        'volumen_llamadas_alto': min((llamadas - 30) / 50, 1) if llamadas > 30 else 0,\n",
    "        'volumen_destinos_alto': min((destinos - 10) / 20, 1) if destinos > 10 else 0,\n",
    "        'llamadas_por_destino': min(llamadas / max(destinos, 1) / 5, 1),\n",
    "        'eficiencia_destinos': min(destinos / max(llamadas * 0.5, 1), 1),\n",
    "        'factor_pais_bajo': 1.5 if categoria in ['Muy_Bajo', 'Bajo'] else 1.0,\n",
    "        'factor_pais_alto': 0.9 if categoria in ['Alto', 'Medio'] else 1.0\n",
    "    }\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Funci√≥n de predicci√≥n id√©ntica\n",
    "def predecir_anomalia_mejorada(pais, linea, llamadas, minutos, destinos, modelo, scaler, umbral, stats_dict, contexto_historico=None):\n",
    "    \"\"\"\n",
    "    Predicci√≥n id√©ntica al modelo original\n",
    "    \"\"\"\n",
    "    # Crear row simulado\n",
    "    row_data = {\n",
    "        'CODIGODEPAIS': pais,\n",
    "        'N_LLAMADAS': llamadas,\n",
    "        'N_MINUTOS': minutos,\n",
    "        'N_DESTINOS': destinos\n",
    "    }\n",
    "    \n",
    "    # Crear features\n",
    "    features = crear_features_contextualizadas_mejorada(row_data, stats_dict)\n",
    "    \n",
    "    # Normalizar\n",
    "    features_scaled = scaler.transform_one(features)\n",
    "    \n",
    "    # Obtener score\n",
    "    score = modelo.score_one(features_scaled)\n",
    "    \n",
    "    # L√≥gica de confirmaci√≥n (id√©ntica al modelo)\n",
    "    es_anomalia_base = score > umbral\n",
    "    \n",
    "    if es_anomalia_base:\n",
    "        # Confirmar diferentes tipos de anomal√≠as\n",
    "        if minutos >= parametros_features['umbral_minutos_extremos']:\n",
    "            es_anomalia_final = True\n",
    "            razon = f\"Minutos extremos ({minutos:.1f} min)\"\n",
    "        elif destinos >= 6 and llamadas >= 12:\n",
    "            es_anomalia_final = True\n",
    "            razon = \"Patr√≥n de spray calling confirmado\"\n",
    "        elif llamadas > 50 or destinos > 15:\n",
    "            es_anomalia_final = True\n",
    "            razon = \"Volumen excepcionalmente alto\"\n",
    "        elif pais not in stats_dict or stats_dict.get(pais, {}).get('CATEGORIA') in ['Muy_Bajo', 'Bajo']:\n",
    "            if destinos >= 4 and llamadas >= 8:\n",
    "                es_anomalia_final = True\n",
    "                razon = \"Actividad sospechosa en pa√≠s de bajo tr√°fico\"\n",
    "            else:\n",
    "                es_anomalia_final = False\n",
    "                razon = \"Actividad baja en pa√≠s de bajo tr√°fico\"\n",
    "        elif destinos < 3:\n",
    "            es_anomalia_final = False\n",
    "            razon = \"Muy pocos destinos (<3)\"\n",
    "        elif destinos / max(llamadas, 1) < 0.15:\n",
    "            es_anomalia_final = False\n",
    "            razon = \"Ratio destinos/llamadas muy bajo\"\n",
    "        elif llamadas < 5:\n",
    "            es_anomalia_final = False\n",
    "            razon = \"Muy pocas llamadas (<5)\"\n",
    "        else:\n",
    "            es_anomalia_final = False\n",
    "            razon = \"No cumple criterios de confirmaci√≥n\"\n",
    "    else:\n",
    "        es_anomalia_final = False\n",
    "        razon = \"Score bajo umbral\"\n",
    "    \n",
    "    # Determinar contexto usando hist√≥rico\n",
    "    if contexto_historico and pais in contexto_historico:\n",
    "        tipo_contexto = contexto_historico[pais]\n",
    "    elif pais in stats_dict:\n",
    "        tipo_contexto = stats_dict[pais]['CATEGORIA']\n",
    "    else:\n",
    "        tipo_contexto = \"Muy_Bajo\"\n",
    "    \n",
    "    return {\n",
    "        'score': score,\n",
    "        'umbral': umbral,\n",
    "        'es_anomalia': es_anomalia_final,\n",
    "        'tipo_contexto': tipo_contexto,\n",
    "        'razon_decision': razon,\n",
    "        'features': features\n",
    "    }\n",
    "\n",
    "print(\"üîß Funciones de predicci√≥n cargadas (id√©nticas al modelo)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfff0f0",
   "metadata": {},
   "source": [
    "# # 19. CARGAR DATASET DE EVALUACI√ìN CON ETIQUETAS DE FRAUDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dd0de81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Cargando dataset de evaluaci√≥n...\n",
      "‚úÖ Dataset cargado - Shape: (102684, 7)\n",
      "üîç AN√ÅLISIS DEL DATASET DE EVALUACI√ìN:\n",
      "üìä Total de registros: 102684\n",
      "üö® Casos de fraude: 2813 (2.74%)\n",
      "‚úÖ Casos normales: 99871 (97.26%)\n",
      "üåç Pa√≠ses √∫nicos: 183\n",
      "üìû L√≠neas √∫nicas: 71752\n",
      "\n",
      "üìä ESTAD√çSTICAS POR CLASE:\n",
      "CASOS NORMALES (FRAUDE = 0):\n",
      "  üìû Llamadas - Min: 0, Max: 200, Media: 1.5\n",
      "  ‚è±Ô∏è Minutos - Min: 0.02, Max: 854.79, Media: 3.5\n",
      "  üéØ Destinos - Min: 0, Max: 121, Media: 1.2\n",
      "\n",
      "CASOS DE FRAUDE (FRAUDE = 1):\n",
      "  üìû Llamadas - Min: 1, Max: 295, Media: 57.3\n",
      "  ‚è±Ô∏è Minutos - Min: 0.02, Max: 459.02, Media: 82.7\n",
      "  üéØ Destinos - Min: 1, Max: 293, Media: 55.5\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüìÇ Cargando dataset de evaluaci√≥n...\")\n",
    "\n",
    "# Verificar que el archivo existe\n",
    "if not os.path.exists(EVALUATION_CSV_PATH):\n",
    "    print(f\"‚ùå Error: Archivo de evaluaci√≥n no encontrado: {EVALUATION_CSV_PATH}\")\n",
    "    print(f\"üìù Por favor, aseg√∫rate de que el archivo exista y contenga las columnas:\")\n",
    "    print(f\"   - FECHA, CODIGODEPAIS, LINEA, N_LLAMADAS, N_MINUTOS, N_DESTINOS, FRAUDE\")\n",
    "    print(f\"   - FRAUDE debe ser 1 (fraudulento) o 0 (normal)\")\n",
    "    exit()\n",
    "\n",
    "# Cargar dataset\n",
    "df_evaluacion = pd.read_csv(EVALUATION_CSV_PATH)\n",
    "\n",
    "# Convertir fecha a datetime si existe\n",
    "if 'FECHA' in df_evaluacion.columns:\n",
    "    df_evaluacion['FECHA'] = pd.to_datetime(df_evaluacion['FECHA'], format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "print(f\"‚úÖ Dataset cargado - Shape: {df_evaluacion.shape}\")\n",
    "\n",
    "# Verificar columnas requeridas\n",
    "columnas_requeridas = ['CODIGODEPAIS', 'LINEA', 'N_LLAMADAS', 'N_MINUTOS', 'N_DESTINOS', 'FRAUDE']\n",
    "columnas_faltantes = [col for col in columnas_requeridas if col not in df_evaluacion.columns]\n",
    "\n",
    "if columnas_faltantes:\n",
    "    print(f\"‚ùå Error: Columnas faltantes: {columnas_faltantes}\")\n",
    "    print(f\"üìã Columnas disponibles: {list(df_evaluacion.columns)}\")\n",
    "    exit()\n",
    "\n",
    "# Verificar valores de FRAUDE\n",
    "valores_fraude = df_evaluacion['FRAUDE'].unique()\n",
    "if not all(v in [0, 1] for v in valores_fraude):\n",
    "    print(f\"‚ùå Error: FRAUDE debe contener solo valores 0 o 1. Valores encontrados: {valores_fraude}\")\n",
    "    exit()\n",
    "\n",
    "print(f\"üîç AN√ÅLISIS DEL DATASET DE EVALUACI√ìN:\")\n",
    "print(f\"üìä Total de registros: {len(df_evaluacion)}\")\n",
    "print(f\"üö® Casos de fraude: {df_evaluacion['FRAUDE'].sum()} ({df_evaluacion['FRAUDE'].mean()*100:.2f}%)\")\n",
    "print(f\"‚úÖ Casos normales: {(df_evaluacion['FRAUDE'] == 0).sum()} ({(df_evaluacion['FRAUDE'] == 0).mean()*100:.2f}%)\")\n",
    "print(f\"üåç Pa√≠ses √∫nicos: {df_evaluacion['CODIGODEPAIS'].nunique()}\")\n",
    "print(f\"üìû L√≠neas √∫nicas: {df_evaluacion['LINEA'].nunique()}\")\n",
    "\n",
    "# Mostrar estad√≠sticas por clase\n",
    "print(f\"\\nüìä ESTAD√çSTICAS POR CLASE:\")\n",
    "print(f\"CASOS NORMALES (FRAUDE = 0):\")\n",
    "normales = df_evaluacion[df_evaluacion['FRAUDE'] == 0]\n",
    "print(f\"  üìû Llamadas - Min: {normales['N_LLAMADAS'].min()}, Max: {normales['N_LLAMADAS'].max()}, Media: {normales['N_LLAMADAS'].mean():.1f}\")\n",
    "print(f\"  ‚è±Ô∏è Minutos - Min: {normales['N_MINUTOS'].min()}, Max: {normales['N_MINUTOS'].max()}, Media: {normales['N_MINUTOS'].mean():.1f}\")\n",
    "print(f\"  üéØ Destinos - Min: {normales['N_DESTINOS'].min()}, Max: {normales['N_DESTINOS'].max()}, Media: {normales['N_DESTINOS'].mean():.1f}\")\n",
    "\n",
    "if df_evaluacion['FRAUDE'].sum() > 0:\n",
    "    print(f\"\\nCASOS DE FRAUDE (FRAUDE = 1):\")\n",
    "    fraudes = df_evaluacion[df_evaluacion['FRAUDE'] == 1]\n",
    "    print(f\"  üìû Llamadas - Min: {fraudes['N_LLAMADAS'].min()}, Max: {fraudes['N_LLAMADAS'].max()}, Media: {fraudes['N_LLAMADAS'].mean():.1f}\")\n",
    "    print(f\"  ‚è±Ô∏è Minutos - Min: {fraudes['N_MINUTOS'].min()}, Max: {fraudes['N_MINUTOS'].max()}, Media: {fraudes['N_MINUTOS'].mean():.1f}\")\n",
    "    print(f\"  üéØ Destinos - Min: {fraudes['N_DESTINOS'].min()}, Max: {fraudes['N_DESTINOS'].max()}, Media: {fraudes['N_DESTINOS'].mean():.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0091646",
   "metadata": {},
   "source": [
    "# # 20. REALIZAR PREDICCIONES EN DATASET DE EVALUACI√ìN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c384bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÆ Realizando predicciones en dataset de evaluaci√≥n...\n",
      "   Procesando: 0/102684 registros\n",
      "   Procesando: 1000/102684 registros\n",
      "   Procesando: 2000/102684 registros\n",
      "   Procesando: 3000/102684 registros\n",
      "   Procesando: 4000/102684 registros\n",
      "   Procesando: 5000/102684 registros\n",
      "   Procesando: 6000/102684 registros\n",
      "   Procesando: 7000/102684 registros\n",
      "   Procesando: 8000/102684 registros\n",
      "   Procesando: 9000/102684 registros\n",
      "   Procesando: 10000/102684 registros\n",
      "   Procesando: 11000/102684 registros\n",
      "   Procesando: 12000/102684 registros\n",
      "   Procesando: 13000/102684 registros\n",
      "   Procesando: 14000/102684 registros\n",
      "   Procesando: 15000/102684 registros\n",
      "   Procesando: 16000/102684 registros\n",
      "   Procesando: 17000/102684 registros\n",
      "   Procesando: 18000/102684 registros\n",
      "   Procesando: 19000/102684 registros\n",
      "   Procesando: 20000/102684 registros\n",
      "   Procesando: 21000/102684 registros\n",
      "   Procesando: 22000/102684 registros\n",
      "   Procesando: 23000/102684 registros\n",
      "   Procesando: 24000/102684 registros\n",
      "   Procesando: 25000/102684 registros\n",
      "   Procesando: 26000/102684 registros\n",
      "   Procesando: 27000/102684 registros\n",
      "   Procesando: 28000/102684 registros\n",
      "   Procesando: 29000/102684 registros\n",
      "   Procesando: 30000/102684 registros\n",
      "   Procesando: 31000/102684 registros\n",
      "   Procesando: 32000/102684 registros\n",
      "   Procesando: 33000/102684 registros\n",
      "   Procesando: 34000/102684 registros\n",
      "   Procesando: 35000/102684 registros\n",
      "   Procesando: 36000/102684 registros\n",
      "   Procesando: 37000/102684 registros\n",
      "   Procesando: 38000/102684 registros\n",
      "   Procesando: 39000/102684 registros\n",
      "   Procesando: 40000/102684 registros\n",
      "   Procesando: 41000/102684 registros\n",
      "   Procesando: 42000/102684 registros\n",
      "   Procesando: 43000/102684 registros\n",
      "   Procesando: 44000/102684 registros\n",
      "   Procesando: 45000/102684 registros\n",
      "   Procesando: 46000/102684 registros\n",
      "   Procesando: 47000/102684 registros\n",
      "   Procesando: 48000/102684 registros\n",
      "   Procesando: 49000/102684 registros\n",
      "   Procesando: 50000/102684 registros\n",
      "   Procesando: 51000/102684 registros\n",
      "   Procesando: 52000/102684 registros\n",
      "   Procesando: 53000/102684 registros\n",
      "   Procesando: 54000/102684 registros\n",
      "   Procesando: 55000/102684 registros\n",
      "   Procesando: 56000/102684 registros\n",
      "   Procesando: 57000/102684 registros\n",
      "   Procesando: 58000/102684 registros\n",
      "   Procesando: 59000/102684 registros\n",
      "   Procesando: 60000/102684 registros\n",
      "   Procesando: 61000/102684 registros\n",
      "   Procesando: 62000/102684 registros\n",
      "   Procesando: 63000/102684 registros\n",
      "   Procesando: 64000/102684 registros\n",
      "   Procesando: 65000/102684 registros\n",
      "   Procesando: 66000/102684 registros\n",
      "   Procesando: 67000/102684 registros\n",
      "   Procesando: 68000/102684 registros\n",
      "   Procesando: 69000/102684 registros\n",
      "   Procesando: 70000/102684 registros\n",
      "   Procesando: 71000/102684 registros\n",
      "   Procesando: 72000/102684 registros\n",
      "   Procesando: 73000/102684 registros\n",
      "   Procesando: 74000/102684 registros\n",
      "   Procesando: 75000/102684 registros\n",
      "   Procesando: 76000/102684 registros\n",
      "   Procesando: 77000/102684 registros\n",
      "   Procesando: 78000/102684 registros\n",
      "   Procesando: 79000/102684 registros\n",
      "   Procesando: 80000/102684 registros\n",
      "   Procesando: 81000/102684 registros\n",
      "   Procesando: 82000/102684 registros\n",
      "   Procesando: 83000/102684 registros\n",
      "   Procesando: 84000/102684 registros\n",
      "   Procesando: 85000/102684 registros\n",
      "   Procesando: 86000/102684 registros\n",
      "   Procesando: 87000/102684 registros\n",
      "   Procesando: 88000/102684 registros\n",
      "   Procesando: 89000/102684 registros\n",
      "   Procesando: 90000/102684 registros\n",
      "   Procesando: 91000/102684 registros\n",
      "   Procesando: 92000/102684 registros\n",
      "   Procesando: 93000/102684 registros\n",
      "   Procesando: 94000/102684 registros\n",
      "   Procesando: 95000/102684 registros\n",
      "   Procesando: 96000/102684 registros\n",
      "   Procesando: 97000/102684 registros\n",
      "   Procesando: 98000/102684 registros\n",
      "   Procesando: 99000/102684 registros\n",
      "   Procesando: 100000/102684 registros\n",
      "   Procesando: 101000/102684 registros\n",
      "   Procesando: 102000/102684 registros\n",
      "‚úÖ Predicciones completadas\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüîÆ Realizando predicciones en dataset de evaluaci√≥n...\")\n",
    "\n",
    "predicciones = []\n",
    "scores = []\n",
    "\n",
    "for contador, (idx, row) in enumerate(df_evaluacion.iterrows()):\n",
    "    if contador % 1000 == 0:\n",
    "        print(f\"   Procesando: {contador}/{len(df_evaluacion)} registros\")\n",
    "    \n",
    "    # Realizar predicci√≥n\n",
    "    resultado = predecir_anomalia_mejorada(\n",
    "        pais=row['CODIGODEPAIS'],\n",
    "        linea=row['LINEA'],\n",
    "        llamadas=row['N_LLAMADAS'],\n",
    "        minutos=row['N_MINUTOS'],\n",
    "        destinos=row['N_DESTINOS'],\n",
    "        modelo=modelo_cargado,\n",
    "        scaler=scaler_cargado,\n",
    "        umbral=umbral_global,\n",
    "        stats_dict=stats_dict,\n",
    "        contexto_historico=contexto_historico\n",
    "    )\n",
    "    \n",
    "    # Guardar predicci√≥n (1 si es anomal√≠a, 0 si es normal)\n",
    "    predicciones.append(1 if resultado['es_anomalia'] else 0)\n",
    "    scores.append(resultado['score'])\n",
    "\n",
    "# Agregar predicciones al dataframe\n",
    "df_evaluacion['PREDICCION'] = predicciones\n",
    "df_evaluacion['SCORE_ANOMALIA'] = scores\n",
    "\n",
    "print(f\"‚úÖ Predicciones completadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31568380",
   "metadata": {},
   "source": [
    "# # 21. CALCULAR M√âTRICAS Y MATRIZ DE CONFUSI√ìN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d15de6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä CALCULANDO M√âTRICAS DE EVALUACI√ìN...\n",
      "üéØ M√âTRICAS DE EVALUACI√ìN:\n",
      "üìà Accuracy (Exactitud): 0.9911 (99.11%)\n",
      "üéØ Precision (Precisi√≥n): 0.8988 (89.88%)\n",
      "üîç Recall (Sensibilidad): 0.7611 (76.11%)\n",
      "‚öñÔ∏è F1-Score: 0.8243 (82.43%)\n",
      "\n",
      "üìã MATRIZ DE CONFUSI√ìN:\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ     REAL \\ PRED ‚îÇ   Normal   ‚îÇ Anomal√≠a ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ      Normal     ‚îÇ    99630   ‚îÇ     241  ‚îÇ\n",
      "‚îÇ     Fraude      ‚îÇ      672   ‚îÇ    2141  ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "\n",
      "üî¢ INTERPRETACI√ìN:\n",
      "‚úÖ Verdaderos Negativos (TN): 99630 - Casos normales correctamente identificados\n",
      "‚ùå Falsos Positivos (FP): 241 - Casos normales incorrectamente marcados como fraude\n",
      "‚ùå Falsos Negativos (FN): 672 - Casos de fraude no detectados\n",
      "‚úÖ Verdaderos Positivos (TP): 2141 - Casos de fraude correctamente detectados\n",
      "üõ°Ô∏è Especificidad (Tasa de Verdaderos Negativos): 0.9976 (99.76%)\n",
      "‚ö†Ô∏è Tasa de Falsos Positivos: 0.0024 (0.24%)\n",
      "‚ö†Ô∏è Tasa de Falsos Negativos: 0.2389 (23.89%)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüìä CALCULANDO M√âTRICAS DE EVALUACI√ìN...\")\n",
    "\n",
    "# Extraer etiquetas reales y predicciones\n",
    "y_true = df_evaluacion['FRAUDE'].values\n",
    "y_pred = df_evaluacion['PREDICCION'].values\n",
    "\n",
    "# Calcular m√©tricas principales\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"üéØ M√âTRICAS DE EVALUACI√ìN:\")\n",
    "print(f\"üìà Accuracy (Exactitud): {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"üéØ Precision (Precisi√≥n): {precision:.4f} ({precision*100:.2f}%)\")\n",
    "print(f\"üîç Recall (Sensibilidad): {recall:.4f} ({recall*100:.2f}%)\")\n",
    "print(f\"‚öñÔ∏è F1-Score: {f1:.4f} ({f1*100:.2f}%)\")\n",
    "\n",
    "# Calcular matriz de confusi√≥n\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f\"\\nüìã MATRIZ DE CONFUSI√ìN:\")\n",
    "print(f\"‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\")\n",
    "print(f\"‚îÇ     REAL \\\\ PRED ‚îÇ   Normal   ‚îÇ Anomal√≠a ‚îÇ\")\n",
    "print(f\"‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\")\n",
    "print(f\"‚îÇ      Normal     ‚îÇ   {tn:6d}   ‚îÇ  {fp:6d}  ‚îÇ\")\n",
    "print(f\"‚îÇ     Fraude      ‚îÇ   {fn:6d}   ‚îÇ  {tp:6d}  ‚îÇ\")\n",
    "print(f\"‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")\n",
    "\n",
    "print(f\"\\nüî¢ INTERPRETACI√ìN:\")\n",
    "print(f\"‚úÖ Verdaderos Negativos (TN): {tn} - Casos normales correctamente identificados\")\n",
    "print(f\"‚ùå Falsos Positivos (FP): {fp} - Casos normales incorrectamente marcados como fraude\")\n",
    "print(f\"‚ùå Falsos Negativos (FN): {fn} - Casos de fraude no detectados\")\n",
    "print(f\"‚úÖ Verdaderos Positivos (TP): {tp} - Casos de fraude correctamente detectados\")\n",
    "\n",
    "# Calcular tasas adicionales\n",
    "if (tn + fp) > 0:\n",
    "    especificidad = tn / (tn + fp)\n",
    "    print(f\"üõ°Ô∏è Especificidad (Tasa de Verdaderos Negativos): {especificidad:.4f} ({especificidad*100:.2f}%)\")\n",
    "\n",
    "if (fp + tn) > 0:\n",
    "    tasa_fp = fp / (fp + tn)\n",
    "    print(f\"‚ö†Ô∏è Tasa de Falsos Positivos: {tasa_fp:.4f} ({tasa_fp*100:.2f}%)\")\n",
    "\n",
    "if (fn + tp) > 0:\n",
    "    tasa_fn = fn / (fn + tp)\n",
    "    print(f\"‚ö†Ô∏è Tasa de Falsos Negativos: {tasa_fn:.4f} ({tasa_fn*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8bbe10",
   "metadata": {},
   "source": [
    "# # 22. Guardar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f78683f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Resultados completos: C:\\Users\\User\\Desktop\\TESIS\\CodigoGithub\\MLTallerProyecto1\\Resultados\\resultados_evaluacion_completa.csv\n"
     ]
    }
   ],
   "source": [
    "resultados_path = os.path.join(RESULTADO, \"resultados_evaluacion_completa.csv\")\n",
    "df_evaluacion.to_csv(resultados_path, index=False)\n",
    "print(f\"üìÑ Resultados completos: {resultados_path}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
