{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80125b9c",
   "metadata": {},
   "source": [
    "# 1. IMPORTAR LIBRER√çAS NECESARIAS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd61c903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Librer√≠as importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from river import anomaly\n",
    "from river import preprocessing\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1132558",
   "metadata": {},
   "source": [
    "# 2. CONFIGURACI√ìN INICIAL Y PAR√ÅMETROS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1088d097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Directorio de modelos: C:\\Users\\User\\Desktop\\TESIS\\CodigoGithub\\MLTallerProyecto1\\Modelos\n",
      "ü§ñ Modelo general con 80 √°rboles, altura 10\n",
      "‚öôÔ∏è Par√°metros configurables definidos\n"
     ]
    }
   ],
   "source": [
    "# Rutas de archivos\n",
    "DATASET_PATH = r\"C:\\Users\\User\\Desktop\\TESIS\\Datasets\\DataSetAgrupadoNoSuper3.csv\"\n",
    "MODELS_PATH = r\"C:\\Users\\User\\Desktop\\TESIS\\CodigoGithub\\MLTallerProyecto1\\Modelos\"\n",
    "RESULTADO = r\"C:\\Users\\User\\Desktop\\TESIS\\CodigoGithub\\MLTallerProyecto1\\Resultados\"\n",
    "\n",
    "\n",
    "# Crear directorio de modelos si no existe\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "\n",
    "# PAR√ÅMETROS AJUSTABLES DEL MODELO ‚öôÔ∏è\n",
    "N_TREES = 80  # üîß AJUSTABLE: 60-120 (m√°s √°rboles = m√°s precisi√≥n pero m√°s lento)\n",
    "TREE_HEIGHT = 10  # üîß AJUSTABLE: 8-15 (mayor altura = patrones m√°s complejos)\n",
    "MIN_RECORDS_WARMUP = 50  # M√≠nimo de registros para warm-up por pa√≠s\n",
    "\n",
    "# PAR√ÅMETROS DE FEATURES ‚öôÔ∏è\n",
    "PESO_MINUTOS_NORMAL = 0.4  # üîß AJUSTABLE: 0.2-0.6 (peso normal de minutos)\n",
    "PESO_MINUTOS_EXTREMOS = 1.5  # üîß AJUSTABLE: 1.2-2.0 (peso cuando minutos son extremos)\n",
    "UMBRAL_MINUTOS_EXTREMOS = 300  # üîß AJUSTABLE: 200-500 (minutos para considerar extremo)\n",
    "PESO_DESTINOS = 1.2  # üîß AJUSTABLE: 1.0-1.5 (importancia de destinos)\n",
    "PESO_SPRAY_RATIO = 1.5  # üîß AJUSTABLE: 1.2-2.0 (importancia del ratio spray)\n",
    "\n",
    "# PAR√ÅMETROS DE UMBRAL ‚öôÔ∏è\n",
    "PERCENTIL_BASE = 99  # üîß AJUSTABLE: 95-99.5 (percentil para umbral)\n",
    "AJUSTE_UMBRAL = 1.0  # üîß AJUSTABLE: 0.8-1.2 (multiplicador del umbral)\n",
    "\n",
    "print(f\"üìÅ Directorio de modelos: {MODELS_PATH}\")\n",
    "print(f\"ü§ñ Modelo general con {N_TREES} √°rboles, altura {TREE_HEIGHT}\")\n",
    "print(f\"‚öôÔ∏è Par√°metros configurables definidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d093646b",
   "metadata": {},
   "source": [
    "# 3. CARGAR Y EXPLORAR EL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9074fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Cargando dataset...\n",
      "üìã Dataset cargado - Shape: (794810, 6)\n",
      "üìÖ Rango de fechas: 2025-03-01 00:00:00 a 2025-04-24 00:00:00\n",
      "üåç Pa√≠ses √∫nicos: 188\n",
      "üìû L√≠neas √∫nicas: 458606\n",
      "\n",
      "üìä Estad√≠sticas generales:\n",
      "üìû Llamadas - Min: 1, Max: 579, Media: 1.9\n",
      "‚è±Ô∏è Minutos - Min: 0.02, Max: 1019.8, Media: 5.8\n",
      "üéØ Destinos - Min: 1, Max: 546, Media: 1.7\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîÑ Cargando dataset...\")\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "\n",
    "# Convertir fecha a datetime\n",
    "df['FECHA'] = pd.to_datetime(df['FECHA'], format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "print(f\"üìã Dataset cargado - Shape: {df.shape}\")\n",
    "print(f\"üìÖ Rango de fechas: {df['FECHA'].min()} a {df['FECHA'].max()}\")\n",
    "print(f\"üåç Pa√≠ses √∫nicos: {df['CODIGODEPAIS'].nunique()}\")\n",
    "print(f\"üìû L√≠neas √∫nicas: {df['LINEA'].nunique()}\")\n",
    "\n",
    "# Mostrar estad√≠sticas generales\n",
    "print(f\"\\nüìä Estad√≠sticas generales:\")\n",
    "print(f\"üìû Llamadas - Min: {df['N_LLAMADAS'].min()}, Max: {df['N_LLAMADAS'].max()}, Media: {df['N_LLAMADAS'].mean():.1f}\")\n",
    "print(f\"‚è±Ô∏è Minutos - Min: {df['N_MINUTOS'].min()}, Max: {df['N_MINUTOS'].max()}, Media: {df['N_MINUTOS'].mean():.1f}\")\n",
    "print(f\"üéØ Destinos - Min: {df['N_DESTINOS'].min()}, Max: {df['N_DESTINOS'].max()}, Media: {df['N_DESTINOS'].mean():.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e496af9",
   "metadata": {},
   "source": [
    "# 4. DIVISI√ìN TEMPORAL PARA WARM-UP Y SCORING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2624add5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÜ Per√≠odo de warm-up: 2025-03\n",
      "üìÜ Per√≠odo de scoring: 2025-04\n",
      "üî¢ Registros warm-up: 450900\n",
      "üî¢ Registros scoring: 343910\n"
     ]
    }
   ],
   "source": [
    "df_sorted = df.sort_values('FECHA')\n",
    "fechas_unicas = sorted(df['FECHA'].dt.to_period('M').unique())\n",
    "\n",
    "if len(fechas_unicas) >= 2:\n",
    "    primer_mes = fechas_unicas[0]\n",
    "    segundo_mes = fechas_unicas[1]\n",
    "    \n",
    "    df_warmup = df[df['FECHA'].dt.to_period('M') == primer_mes].copy()\n",
    "    df_scoring = df[df['FECHA'].dt.to_period('M') == segundo_mes].copy()\n",
    "    \n",
    "    print(f\"\\nüìÜ Per√≠odo de warm-up: {primer_mes}\")\n",
    "    print(f\"üìÜ Per√≠odo de scoring: {segundo_mes}\")\n",
    "else:\n",
    "    # Divisi√≥n por mediana de fechas\n",
    "    fecha_corte = df_sorted['FECHA'].quantile(0.5)\n",
    "    df_warmup = df[df['FECHA'] <= fecha_corte].copy()\n",
    "    df_scoring = df[df['FECHA'] > fecha_corte].copy()\n",
    "    \n",
    "    print(f\"\\nüìÜ Divisi√≥n por fecha de corte: {fecha_corte}\")\n",
    "\n",
    "print(f\"üî¢ Registros warm-up: {len(df_warmup)}\")\n",
    "print(f\"üî¢ Registros scoring: {len(df_scoring)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290147ff",
   "metadata": {},
   "source": [
    "# 5. AN√ÅLISIS DE CONTEXTO POR PA√çS (PARA NORMALIZACI√ìN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7d1410a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üåç Analizando contexto por pa√≠s...\n",
      "üìä Distribuci√≥n de pa√≠ses por tr√°fico:\n",
      "CATEGORIA\n",
      "Muy_Bajo    129\n",
      "Bajo         21\n",
      "Medio        20\n",
      "Alto         18\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üîç Ejemplos por categor√≠a de tr√°fico:\n",
      "\n",
      "Muy_Bajo (129 pa√≠ses):\n",
      "              REGISTROS  LLAMADAS_MEAN  DESTINOS_MEAN  MINUTOS_MEAN\n",
      "CODIGODEPAIS                                                       \n",
      "27                   26           1.27           1.15          0.40\n",
      "40                   24           1.38           1.00          0.40\n",
      "62                   29           1.07           1.07          0.14\n",
      "\n",
      "Bajo (21 pa√≠ses):\n",
      "              REGISTROS  LLAMADAS_MEAN  DESTINOS_MEAN  MINUTOS_MEAN\n",
      "CODIGODEPAIS                                                       \n",
      "20                   81           1.22           1.01          0.18\n",
      "30                   98           1.37           1.16          2.35\n",
      "36                  120           1.23           1.02          0.10\n",
      "\n",
      "Medio (20 pa√≠ses):\n",
      "              REGISTROS  LLAMADAS_MEAN  DESTINOS_MEAN  MINUTOS_MEAN\n",
      "CODIGODEPAIS                                                       \n",
      "31                  313           1.59           1.06          3.75\n",
      "32                  216           1.37           1.06          1.36\n",
      "41                  364           1.25           1.06          3.48\n",
      "\n",
      "Alto (18 pa√≠ses):\n",
      "              REGISTROS  LLAMADAS_MEAN  DESTINOS_MEAN  MINUTOS_MEAN\n",
      "CODIGODEPAIS                                                       \n",
      "1                 82438           2.01           1.20         11.71\n",
      "7                  3653           1.17           1.06          0.22\n",
      "33                 1130           2.15           1.11          2.32\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüåç Analizando contexto por pa√≠s...\")\n",
    "\n",
    "# Calcular estad√≠sticas por pa√≠s en per√≠odo de warm-up\n",
    "stats_por_pais = df_warmup.groupby('CODIGODEPAIS').agg({\n",
    "    'N_LLAMADAS': ['count', 'mean', 'std', lambda x: x.quantile(0.90), lambda x: x.quantile(0.95)],\n",
    "    'N_MINUTOS': ['mean', 'std', lambda x: x.quantile(0.90), lambda x: x.quantile(0.95)],\n",
    "    'N_DESTINOS': ['mean', 'std', lambda x: x.quantile(0.90), lambda x: x.quantile(0.95)]\n",
    "}).round(2)\n",
    "\n",
    "stats_por_pais.columns = ['REGISTROS', 'LLAMADAS_MEAN', 'LLAMADAS_STD', 'LLAMADAS_P90', 'LLAMADAS_P95',\n",
    "                         'MINUTOS_MEAN', 'MINUTOS_STD', 'MINUTOS_P90', 'MINUTOS_P95',\n",
    "                         'DESTINOS_MEAN', 'DESTINOS_STD', 'DESTINOS_P90', 'DESTINOS_P95']\n",
    "\n",
    "# Clasificar pa√≠ses por volumen de tr√°fico\n",
    "stats_por_pais['CATEGORIA'] = pd.cut(stats_por_pais['REGISTROS'], \n",
    "                                   bins=[0, 50, 200, 1000, float('inf')],\n",
    "                                   labels=['Muy_Bajo', 'Bajo', 'Medio', 'Alto'])\n",
    "\n",
    "print(f\"üìä Distribuci√≥n de pa√≠ses por tr√°fico:\")\n",
    "print(stats_por_pais['CATEGORIA'].value_counts())\n",
    "\n",
    "# Mostrar ejemplos por categor√≠a\n",
    "print(f\"\\nüîç Ejemplos por categor√≠a de tr√°fico:\")\n",
    "for categoria in ['Muy_Bajo', 'Bajo', 'Medio', 'Alto']:\n",
    "    paises_cat = stats_por_pais[stats_por_pais['CATEGORIA'] == categoria]\n",
    "    if len(paises_cat) > 0:\n",
    "        print(f\"\\n{categoria} ({len(paises_cat)} pa√≠ses):\")\n",
    "        print(paises_cat[['REGISTROS', 'LLAMADAS_MEAN', 'DESTINOS_MEAN', 'MINUTOS_MEAN']].head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bb3c62",
   "metadata": {},
   "source": [
    "# 6. FUNCI√ìN PARA CREAR CARACTER√çSTICAS CONTEXTUALIZADAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3780762c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Funci√≥n de features mejorada definida (detecci√≥n de minutos extremos)\n"
     ]
    }
   ],
   "source": [
    "def crear_features_contextualizadas_mejorada(row, stats_pais_dict):\n",
    "    \"\"\"\n",
    "    Crea caracter√≠sticas balanceadas que detecten minutos extremos y spray calling\n",
    "    \"\"\"\n",
    "    pais = row['CODIGODEPAIS']\n",
    "    llamadas = row['N_LLAMADAS']\n",
    "    minutos = row['N_MINUTOS']\n",
    "    destinos = row['N_DESTINOS']\n",
    "    \n",
    "    # Obtener contexto del pa√≠s (si existe)\n",
    "    if pais in stats_pais_dict:\n",
    "        pais_stats = stats_pais_dict[pais]\n",
    "        categoria = pais_stats['CATEGORIA']\n",
    "        \n",
    "        # Normalizar por el contexto del pa√≠s\n",
    "        llamadas_norm = min(llamadas / max(pais_stats['LLAMADAS_P95'], 1), 1.5)\n",
    "        destinos_norm = min(destinos / max(pais_stats['DESTINOS_P95'], 1), 1.5)\n",
    "        \n",
    "        # MEJORA: Detecci√≥n inteligente de minutos extremos\n",
    "        minutos_p90 = pais_stats.get('MINUTOS_P90', pais_stats['MINUTOS_P95'] * 0.9)\n",
    "        minutos_p95 = pais_stats['MINUTOS_P95']\n",
    "        \n",
    "        # Transformaci√≥n adaptativa de minutos\n",
    "        if minutos >= UMBRAL_MINUTOS_EXTREMOS:  # üîß Minutos extremos\n",
    "            minutos_norm = min(minutos / max(minutos_p90, 1), 3.0)  # Mayor rango para extremos\n",
    "            peso_minutos = PESO_MINUTOS_EXTREMOS  # Peso alto para extremos\n",
    "        else:\n",
    "            minutos_norm = min(np.log1p(minutos) / np.log1p(max(minutos_p90, 1)), 1.2)\n",
    "            peso_minutos = PESO_MINUTOS_NORMAL  # Peso normal\n",
    "            \n",
    "    else:\n",
    "        # Pa√≠s nuevo - SIEMPRE clasificar como 'Muy_Bajo'\n",
    "        categoria = 'Muy_Bajo'\n",
    "        llamadas_norm = min(llamadas / 10, 2.0)  # M√°s sensible para pa√≠ses nuevos\n",
    "        destinos_norm = min(destinos / 5, 2.0)   # M√°s sensible para pa√≠ses nuevos\n",
    "        \n",
    "        # Para pa√≠ses nuevos, ser m√°s sensible a minutos altos\n",
    "        if minutos >= UMBRAL_MINUTOS_EXTREMOS:\n",
    "            minutos_norm = min(minutos / 50, 3.0)  # Muy sensible a minutos extremos\n",
    "            peso_minutos = PESO_MINUTOS_EXTREMOS * 1.2  # Peso extra para pa√≠ses nuevos\n",
    "        else:\n",
    "            minutos_norm = min(np.log1p(minutos) / np.log1p(60), 1.2)\n",
    "            peso_minutos = PESO_MINUTOS_NORMAL\n",
    "    \n",
    "    # Features principales - REBALANCEADAS con detecci√≥n de extremos\n",
    "    features = {\n",
    "        # 1. Valores normalizados con peso adaptativo\n",
    "        'llamadas_norm': llamadas_norm * 0.8,\n",
    "        'destinos_norm': destinos_norm * PESO_DESTINOS,  # üîß Ajustable\n",
    "        'minutos_norm': minutos_norm * peso_minutos,     # üîß Peso adaptativo\n",
    "        \n",
    "        # 2. Ratios cr√≠ticos para fraude\n",
    "        'diversidad_destinos': min(destinos / max(llamadas, 1), 1.0),\n",
    "        'spray_ratio': min(destinos / max(llamadas, 1) * PESO_SPRAY_RATIO, 1.0) if destinos >= 5 else 0,\n",
    "        \n",
    "        # 3. NUEVA: Detecci√≥n espec√≠fica de minutos extremos\n",
    "        'minutos_extremos': 1.0 if minutos >= UMBRAL_MINUTOS_EXTREMOS else 0.0,\n",
    "        'minutos_sospechosos': min((minutos - 200) / 300, 1.0) if minutos > 200 else 0.0,\n",
    "        \n",
    "        # 4. Patrones de fraude\n",
    "        'patron_spray_fuerte': 1.0 if (destinos >= 10 and llamadas >= 20) else 0.0,\n",
    "        'patron_spray_medio': 0.5 if (destinos >= 6 and llamadas >= 12) else 0.0,\n",
    "        'alta_diversidad': min(destinos / 12, 1) if destinos >= 5 else 0,\n",
    "        \n",
    "        # 5. Indicadores de volumen an√≥malo\n",
    "        'volumen_llamadas_alto': min((llamadas - 30) / 50, 1) if llamadas > 30 else 0,\n",
    "        'volumen_destinos_alto': min((destinos - 10) / 20, 1) if destinos > 10 else 0,\n",
    "        \n",
    "        # 6. Caracter√≠sticas de comportamiento\n",
    "        'llamadas_por_destino': min(llamadas / max(destinos, 1) / 5, 1),\n",
    "        'eficiencia_destinos': min(destinos / max(llamadas * 0.5, 1), 1),\n",
    "        \n",
    "        # 7. MEJORA: Ajuste por contexto de pa√≠s\n",
    "        'factor_pais_bajo': 1.5 if categoria in ['Muy_Bajo', 'Bajo'] else 1.0,  # M√°s sensible\n",
    "        'factor_pais_alto': 0.9 if categoria in ['Alto', 'Medio'] else 1.0      # Menos sensible\n",
    "    }\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Convertir stats a diccionario para b√∫squeda r√°pida\n",
    "stats_dict = {}\n",
    "for pais, row in stats_por_pais.iterrows():\n",
    "    stats_dict[pais] = row.to_dict()\n",
    "\n",
    "print(\"üîß Funci√≥n de features mejorada definida (detecci√≥n de minutos extremos)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0fc5f7",
   "metadata": {},
   "source": [
    "# 7. ENTRENAMIENTO DEL MODELO GENERAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18ee7735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Entrenando modelo con detecci√≥n de extremos...\n",
      "üîÑ Procesando con features mejoradas...\n",
      "   Procesado: 0/450900 registros\n",
      "   Procesado: 2000/450900 registros\n",
      "   Procesado: 4000/450900 registros\n",
      "   Procesado: 6000/450900 registros\n",
      "   Procesado: 8000/450900 registros\n",
      "   Procesado: 10000/450900 registros\n",
      "   Procesado: 12000/450900 registros\n",
      "   Procesado: 14000/450900 registros\n",
      "   Procesado: 16000/450900 registros\n",
      "   Procesado: 18000/450900 registros\n",
      "   Procesado: 20000/450900 registros\n",
      "   Procesado: 22000/450900 registros\n",
      "   Procesado: 24000/450900 registros\n",
      "   Procesado: 26000/450900 registros\n",
      "   Procesado: 28000/450900 registros\n",
      "   Procesado: 30000/450900 registros\n",
      "   Procesado: 32000/450900 registros\n",
      "   Procesado: 34000/450900 registros\n",
      "   Procesado: 36000/450900 registros\n",
      "   Procesado: 38000/450900 registros\n",
      "   Procesado: 40000/450900 registros\n",
      "   Procesado: 42000/450900 registros\n",
      "   Procesado: 44000/450900 registros\n",
      "   Procesado: 46000/450900 registros\n",
      "   Procesado: 48000/450900 registros\n",
      "   Procesado: 50000/450900 registros\n",
      "   Procesado: 52000/450900 registros\n",
      "   Procesado: 54000/450900 registros\n",
      "   Procesado: 56000/450900 registros\n",
      "   Procesado: 58000/450900 registros\n",
      "   Procesado: 60000/450900 registros\n",
      "   Procesado: 62000/450900 registros\n",
      "   Procesado: 64000/450900 registros\n",
      "   Procesado: 66000/450900 registros\n",
      "   Procesado: 68000/450900 registros\n",
      "   Procesado: 70000/450900 registros\n",
      "   Procesado: 72000/450900 registros\n",
      "   Procesado: 74000/450900 registros\n",
      "   Procesado: 76000/450900 registros\n",
      "   Procesado: 78000/450900 registros\n",
      "   Procesado: 80000/450900 registros\n",
      "   Procesado: 82000/450900 registros\n",
      "   Procesado: 84000/450900 registros\n",
      "   Procesado: 86000/450900 registros\n",
      "   Procesado: 88000/450900 registros\n",
      "   Procesado: 90000/450900 registros\n",
      "   Procesado: 92000/450900 registros\n",
      "   Procesado: 94000/450900 registros\n",
      "   Procesado: 96000/450900 registros\n",
      "   Procesado: 98000/450900 registros\n",
      "   Procesado: 100000/450900 registros\n",
      "   Procesado: 102000/450900 registros\n",
      "   Procesado: 104000/450900 registros\n",
      "   Procesado: 106000/450900 registros\n",
      "   Procesado: 108000/450900 registros\n",
      "   Procesado: 110000/450900 registros\n",
      "   Procesado: 112000/450900 registros\n",
      "   Procesado: 114000/450900 registros\n",
      "   Procesado: 116000/450900 registros\n",
      "   Procesado: 118000/450900 registros\n",
      "   Procesado: 120000/450900 registros\n",
      "   Procesado: 122000/450900 registros\n",
      "   Procesado: 124000/450900 registros\n",
      "   Procesado: 126000/450900 registros\n",
      "   Procesado: 128000/450900 registros\n",
      "   Procesado: 130000/450900 registros\n",
      "   Procesado: 132000/450900 registros\n",
      "   Procesado: 134000/450900 registros\n",
      "   Procesado: 136000/450900 registros\n",
      "   Procesado: 138000/450900 registros\n",
      "   Procesado: 140000/450900 registros\n",
      "   Procesado: 142000/450900 registros\n",
      "   Procesado: 144000/450900 registros\n",
      "   Procesado: 146000/450900 registros\n",
      "   Procesado: 148000/450900 registros\n",
      "   Procesado: 150000/450900 registros\n",
      "   Procesado: 152000/450900 registros\n",
      "   Procesado: 154000/450900 registros\n",
      "   Procesado: 156000/450900 registros\n",
      "   Procesado: 158000/450900 registros\n",
      "   Procesado: 160000/450900 registros\n",
      "   Procesado: 162000/450900 registros\n",
      "   Procesado: 164000/450900 registros\n",
      "   Procesado: 166000/450900 registros\n",
      "   Procesado: 168000/450900 registros\n",
      "   Procesado: 170000/450900 registros\n",
      "   Procesado: 172000/450900 registros\n",
      "   Procesado: 174000/450900 registros\n",
      "   Procesado: 176000/450900 registros\n",
      "   Procesado: 178000/450900 registros\n",
      "   Procesado: 180000/450900 registros\n",
      "   Procesado: 182000/450900 registros\n",
      "   Procesado: 184000/450900 registros\n",
      "   Procesado: 186000/450900 registros\n",
      "   Procesado: 188000/450900 registros\n",
      "   Procesado: 190000/450900 registros\n",
      "   Procesado: 192000/450900 registros\n",
      "   Procesado: 194000/450900 registros\n",
      "   Procesado: 196000/450900 registros\n",
      "   Procesado: 198000/450900 registros\n",
      "   Procesado: 200000/450900 registros\n",
      "   Procesado: 202000/450900 registros\n",
      "   Procesado: 204000/450900 registros\n",
      "   Procesado: 206000/450900 registros\n",
      "   Procesado: 208000/450900 registros\n",
      "   Procesado: 210000/450900 registros\n",
      "   Procesado: 212000/450900 registros\n",
      "   Procesado: 214000/450900 registros\n",
      "   Procesado: 216000/450900 registros\n",
      "   Procesado: 218000/450900 registros\n",
      "   Procesado: 220000/450900 registros\n",
      "   Procesado: 222000/450900 registros\n",
      "   Procesado: 224000/450900 registros\n",
      "   Procesado: 226000/450900 registros\n",
      "   Procesado: 228000/450900 registros\n",
      "   Procesado: 230000/450900 registros\n",
      "   Procesado: 232000/450900 registros\n",
      "   Procesado: 234000/450900 registros\n",
      "   Procesado: 236000/450900 registros\n",
      "   Procesado: 238000/450900 registros\n",
      "   Procesado: 240000/450900 registros\n",
      "   Procesado: 242000/450900 registros\n",
      "   Procesado: 244000/450900 registros\n",
      "   Procesado: 246000/450900 registros\n",
      "   Procesado: 248000/450900 registros\n",
      "   Procesado: 250000/450900 registros\n",
      "   Procesado: 252000/450900 registros\n",
      "   Procesado: 254000/450900 registros\n",
      "   Procesado: 256000/450900 registros\n",
      "   Procesado: 258000/450900 registros\n",
      "   Procesado: 260000/450900 registros\n",
      "   Procesado: 262000/450900 registros\n",
      "   Procesado: 264000/450900 registros\n",
      "   Procesado: 266000/450900 registros\n",
      "   Procesado: 268000/450900 registros\n",
      "   Procesado: 270000/450900 registros\n",
      "   Procesado: 272000/450900 registros\n",
      "   Procesado: 274000/450900 registros\n",
      "   Procesado: 276000/450900 registros\n",
      "   Procesado: 278000/450900 registros\n",
      "   Procesado: 280000/450900 registros\n",
      "   Procesado: 282000/450900 registros\n",
      "   Procesado: 284000/450900 registros\n",
      "   Procesado: 286000/450900 registros\n",
      "   Procesado: 288000/450900 registros\n",
      "   Procesado: 290000/450900 registros\n",
      "   Procesado: 292000/450900 registros\n",
      "   Procesado: 294000/450900 registros\n",
      "   Procesado: 296000/450900 registros\n",
      "   Procesado: 298000/450900 registros\n",
      "   Procesado: 300000/450900 registros\n",
      "   Procesado: 302000/450900 registros\n",
      "   Procesado: 304000/450900 registros\n",
      "   Procesado: 306000/450900 registros\n",
      "   Procesado: 308000/450900 registros\n",
      "   Procesado: 310000/450900 registros\n",
      "   Procesado: 312000/450900 registros\n",
      "   Procesado: 314000/450900 registros\n",
      "   Procesado: 316000/450900 registros\n",
      "   Procesado: 318000/450900 registros\n",
      "   Procesado: 320000/450900 registros\n",
      "   Procesado: 322000/450900 registros\n",
      "   Procesado: 324000/450900 registros\n",
      "   Procesado: 326000/450900 registros\n",
      "   Procesado: 328000/450900 registros\n",
      "   Procesado: 330000/450900 registros\n",
      "   Procesado: 332000/450900 registros\n",
      "   Procesado: 334000/450900 registros\n",
      "   Procesado: 336000/450900 registros\n",
      "   Procesado: 338000/450900 registros\n",
      "   Procesado: 340000/450900 registros\n",
      "   Procesado: 342000/450900 registros\n",
      "   Procesado: 344000/450900 registros\n",
      "   Procesado: 346000/450900 registros\n",
      "   Procesado: 348000/450900 registros\n",
      "   Procesado: 350000/450900 registros\n",
      "   Procesado: 352000/450900 registros\n",
      "   Procesado: 354000/450900 registros\n",
      "   Procesado: 356000/450900 registros\n",
      "   Procesado: 358000/450900 registros\n",
      "   Procesado: 360000/450900 registros\n",
      "   Procesado: 362000/450900 registros\n",
      "   Procesado: 364000/450900 registros\n",
      "   Procesado: 366000/450900 registros\n",
      "   Procesado: 368000/450900 registros\n",
      "   Procesado: 370000/450900 registros\n",
      "   Procesado: 372000/450900 registros\n",
      "   Procesado: 374000/450900 registros\n",
      "   Procesado: 376000/450900 registros\n",
      "   Procesado: 378000/450900 registros\n",
      "   Procesado: 380000/450900 registros\n",
      "   Procesado: 382000/450900 registros\n",
      "   Procesado: 384000/450900 registros\n",
      "   Procesado: 386000/450900 registros\n",
      "   Procesado: 388000/450900 registros\n",
      "   Procesado: 390000/450900 registros\n",
      "   Procesado: 392000/450900 registros\n",
      "   Procesado: 394000/450900 registros\n",
      "   Procesado: 396000/450900 registros\n",
      "   Procesado: 398000/450900 registros\n",
      "   Procesado: 400000/450900 registros\n",
      "   Procesado: 402000/450900 registros\n",
      "   Procesado: 404000/450900 registros\n",
      "   Procesado: 406000/450900 registros\n",
      "   Procesado: 408000/450900 registros\n",
      "   Procesado: 410000/450900 registros\n",
      "   Procesado: 412000/450900 registros\n",
      "   Procesado: 414000/450900 registros\n",
      "   Procesado: 416000/450900 registros\n",
      "   Procesado: 418000/450900 registros\n",
      "   Procesado: 420000/450900 registros\n",
      "   Procesado: 422000/450900 registros\n",
      "   Procesado: 424000/450900 registros\n",
      "   Procesado: 426000/450900 registros\n",
      "   Procesado: 428000/450900 registros\n",
      "   Procesado: 430000/450900 registros\n",
      "   Procesado: 432000/450900 registros\n",
      "   Procesado: 434000/450900 registros\n",
      "   Procesado: 436000/450900 registros\n",
      "   Procesado: 438000/450900 registros\n",
      "   Procesado: 440000/450900 registros\n",
      "   Procesado: 442000/450900 registros\n",
      "   Procesado: 444000/450900 registros\n",
      "   Procesado: 446000/450900 registros\n",
      "   Procesado: 448000/450900 registros\n",
      "   Procesado: 450000/450900 registros\n",
      "‚úÖ Entrenamiento completado\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nü§ñ Entrenando modelo con detecci√≥n de extremos...\")\n",
    "\n",
    "# Crear modelo con par√°metros configurables\n",
    "modelo_mejorado = anomaly.HalfSpaceTrees(\n",
    "    n_trees=N_TREES,\n",
    "    height=TREE_HEIGHT,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Crear scaler\n",
    "scaler_mejorado = preprocessing.StandardScaler()\n",
    "\n",
    "# Procesar datos con features mejoradas\n",
    "scores_mejorados = []\n",
    "features_mejoradas = []\n",
    "\n",
    "print(\"üîÑ Procesando con features mejoradas...\")\n",
    "for contador, (idx, row) in enumerate(df_warmup.iterrows()):\n",
    "    if contador % 2000 == 0:\n",
    "        print(f\"   Procesado: {contador}/{len(df_warmup)} registros\")\n",
    "    \n",
    "    # Usar funci√≥n mejorada\n",
    "    features = crear_features_contextualizadas_mejorada(row, stats_dict)\n",
    "    \n",
    "    # Normalizar\n",
    "    scaler_mejorado.learn_one(features)\n",
    "    features_scaled = scaler_mejorado.transform_one(features)\n",
    "    \n",
    "    # Score y entrenamiento\n",
    "    score = modelo_mejorado.score_one(features_scaled)\n",
    "    scores_mejorados.append(score)\n",
    "    features_mejoradas.append(features)\n",
    "    \n",
    "    modelo_mejorado.learn_one(features_scaled)\n",
    "\n",
    "print(\"‚úÖ Entrenamiento completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddd50b1",
   "metadata": {},
   "source": [
    "# 8. CALCULAR UMBRAL GLOBAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c851e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä AN√ÅLISIS DE UMBRALES POSIBLES:\n",
      "P90: Umbral=0.8191, Tasa=10.00%\n",
      "P92: Umbral=0.8479, Tasa=8.00%\n",
      "P94: Umbral=0.8840, Tasa=6.00%\n",
      "P95: Umbral=0.8990, Tasa=5.00%\n",
      "P96: Umbral=0.9115, Tasa=4.00%\n",
      "P97: Umbral=0.9233, Tasa=3.00%\n",
      "P98: Umbral=0.9417, Tasa=2.00%\n",
      "P99: Umbral=0.9724, Tasa=1.00%\n",
      "P99.5: Umbral=0.9967, Tasa=0.50%\n",
      "\n",
      "üéØ UMBRAL SELECCIONADO:\n",
      "üìä Percentil base: P99\n",
      "üî¢ Umbral final: 0.9724\n",
      "üìà Tasa estimada: 1.00%\n",
      "‚öôÔ∏è Ajuste aplicado: 1.0\n"
     ]
    }
   ],
   "source": [
    "# An√°lisis detallado de scores para encontrar umbral √≥ptimo\n",
    "scores_array = np.array(scores_mejorados)\n",
    "\n",
    "# Calcular m√∫ltiples percentiles\n",
    "percentiles = [90, 92, 94, 95, 96, 97, 98, 99, 99.5]\n",
    "umbrales = {}\n",
    "\n",
    "print(f\"\\nüìä AN√ÅLISIS DE UMBRALES POSIBLES:\")\n",
    "for p in percentiles:\n",
    "    umbral = np.percentile(scores_array, p)\n",
    "    tasa_anomalia = (scores_array > umbral).mean() * 100\n",
    "    umbrales[p] = {'umbral': umbral, 'tasa': tasa_anomalia}\n",
    "    print(f\"P{p}: Umbral={umbral:.4f}, Tasa={tasa_anomalia:.2f}%\")\n",
    "\n",
    "# Seleccionar umbral basado en PERCENTIL_BASE configurado\n",
    "umbral_base = umbrales[PERCENTIL_BASE]['umbral']\n",
    "umbral_objetivo = umbral_base * AJUSTE_UMBRAL  # üîß Ajuste configurable\n",
    "\n",
    "# Calcular tasa final\n",
    "tasa_objetivo = (scores_array > umbral_objetivo).mean() * 100\n",
    "\n",
    "print(f\"\\nüéØ UMBRAL SELECCIONADO:\")\n",
    "print(f\"üìä Percentil base: P{PERCENTIL_BASE}\")\n",
    "print(f\"üî¢ Umbral final: {umbral_objetivo:.4f}\")\n",
    "print(f\"üìà Tasa estimada: {tasa_objetivo:.2f}%\")\n",
    "print(f\"‚öôÔ∏è Ajuste aplicado: {AJUSTE_UMBRAL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c6265f",
   "metadata": {},
   "source": [
    "# 9. GUARDAR MODELO Y CONFIGURACI√ìN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0852dd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Guardando modelo mejorado...\n",
      "üìã Contextos hist√≥ricos guardados para 188 pa√≠ses\n",
      "‚úÖ Modelo mejorado guardado exitosamente\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüíæ Guardando modelo mejorado...\")\n",
    "\n",
    "# Guardar modelo\n",
    "modelo_path = os.path.join(MODELS_PATH, \"modelo_general.pkl\")\n",
    "with open(modelo_path, 'wb') as f:\n",
    "    pickle.dump(modelo_mejorado, f)\n",
    "\n",
    "# Guardar scaler\n",
    "scaler_path = os.path.join(MODELS_PATH, \"scaler_general.pkl\")\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler_mejorado, f)\n",
    "\n",
    "# Guardar configuraci√≥n\n",
    "config_general = {\n",
    "    'umbral_global': umbral_objetivo,\n",
    "    'stats_por_pais': stats_dict,\n",
    "    'fecha_entrenamiento': datetime.now().isoformat(),\n",
    "    'n_trees': N_TREES,\n",
    "    'tree_height': TREE_HEIGHT,\n",
    "    'registros_entrenamiento': len(df_warmup),\n",
    "    'paises_entrenamiento': df_warmup['CODIGODEPAIS'].nunique(),\n",
    "    'parametros_features': {\n",
    "        'peso_minutos_normal': PESO_MINUTOS_NORMAL,\n",
    "        'peso_minutos_extremos': PESO_MINUTOS_EXTREMOS,\n",
    "        'umbral_minutos_extremos': UMBRAL_MINUTOS_EXTREMOS,\n",
    "        'peso_destinos': PESO_DESTINOS,\n",
    "        'peso_spray_ratio': PESO_SPRAY_RATIO\n",
    "    },\n",
    "    'parametros_umbral': {\n",
    "        'percentil_base': PERCENTIL_BASE,\n",
    "        'ajuste_umbral': AJUSTE_UMBRAL\n",
    "    }\n",
    "}\n",
    "\n",
    "contexto_historico = {}\n",
    "for pais in stats_dict.keys():\n",
    "    contexto_historico[pais] = stats_dict[pais]['CATEGORIA']\n",
    "\n",
    "# Agregar al config_general:\n",
    "config_general['contexto_historico'] = contexto_historico\n",
    "\n",
    "print(f\"üìã Contextos hist√≥ricos guardados para {len(contexto_historico)} pa√≠ses\")\n",
    "\n",
    "config_path = os.path.join(MODELS_PATH, \"config_modelo_general.pkl\")\n",
    "with open(config_path, 'wb') as f:\n",
    "    pickle.dump(config_general, f)\n",
    "\n",
    "print(\"‚úÖ Modelo mejorado guardado exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fc5397",
   "metadata": {},
   "source": [
    "# 10. FUNCI√ìN DE PREDICCI√ìN GENERAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9859273b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÆ Funci√≥n de predicci√≥n mejorada definida\n"
     ]
    }
   ],
   "source": [
    "def predecir_anomalia_mejorada(pais, linea, llamadas, minutos, destinos, modelo, scaler, umbral, stats_dict, contexto_historico=None):\n",
    "    \"\"\"\n",
    "    Predicci√≥n con detecci√≥n inteligente de minutos extremos y spray calling\n",
    "    \"\"\"\n",
    "    # Crear row simulado\n",
    "    row_data = {\n",
    "        'CODIGODEPAIS': pais,\n",
    "        'N_LLAMADAS': llamadas,\n",
    "        'N_MINUTOS': minutos,\n",
    "        'N_DESTINOS': destinos\n",
    "    }\n",
    "    \n",
    "    # Crear features mejoradas\n",
    "    features = crear_features_contextualizadas_mejorada(row_data, stats_dict)\n",
    "    \n",
    "    # Normalizar\n",
    "    features_scaled = scaler.transform_one(features)\n",
    "    \n",
    "    # Obtener score\n",
    "    score = modelo.score_one(features_scaled)\n",
    "    \n",
    "    # L√ìGICA MEJORADA PARA CONFIRMACI√ìN DE ANOMAL√çAS\n",
    "    es_anomalia_base = score > umbral\n",
    "    \n",
    "    if es_anomalia_base:\n",
    "        # Confirmar diferentes tipos de anomal√≠as\n",
    "        \n",
    "        # Tipo 1: Minutos extremos (NUEVA DETECCI√ìN)\n",
    "        if minutos >= UMBRAL_MINUTOS_EXTREMOS:\n",
    "            es_anomalia_final = True\n",
    "            razon = f\"Minutos extremos ({minutos:.1f} min)\"\n",
    "        \n",
    "        # Tipo 2: Spray calling confirmado\n",
    "        elif destinos >= 6 and llamadas >= 12:\n",
    "            es_anomalia_final = True\n",
    "            razon = \"Patr√≥n de spray calling confirmado\"\n",
    "        \n",
    "        # Tipo 3: Volumen excepcionalmente alto\n",
    "        elif llamadas > 50 or destinos > 15:\n",
    "            es_anomalia_final = True\n",
    "            razon = \"Volumen excepcionalmente alto\"\n",
    "        \n",
    "        # Tipo 4: Pa√≠s de bajo tr√°fico con actividad sospechosa\n",
    "        elif pais not in stats_dict or stats_dict.get(pais, {}).get('CATEGORIA') in ['Muy_Bajo', 'Bajo']:\n",
    "            if destinos >= 4 and llamadas >= 8:\n",
    "                es_anomalia_final = True\n",
    "                razon = \"Actividad sospechosa en pa√≠s de bajo tr√°fico\"\n",
    "            else:\n",
    "                es_anomalia_final = False\n",
    "                razon = \"Actividad baja en pa√≠s de bajo tr√°fico\"\n",
    "        \n",
    "        # Reglas de exclusi√≥n\n",
    "        elif destinos < 3:\n",
    "            es_anomalia_final = False\n",
    "            razon = \"Muy pocos destinos (<3)\"\n",
    "        elif destinos / max(llamadas, 1) < 0.15:\n",
    "            es_anomalia_final = False\n",
    "            razon = \"Ratio destinos/llamadas muy bajo\"\n",
    "        elif llamadas < 5:\n",
    "            es_anomalia_final = False\n",
    "            razon = \"Muy pocas llamadas (<5)\"\n",
    "        else:\n",
    "            es_anomalia_final = False\n",
    "            razon = \"No cumple criterios de confirmaci√≥n\"\n",
    "    else:\n",
    "        es_anomalia_final = False\n",
    "        razon = \"Score bajo umbral\"\n",
    "    \n",
    "    # Determinar contexto\n",
    "    if contexto_historico and pais in contexto_historico:\n",
    "        tipo_contexto = contexto_historico[pais]  # Usar contexto hist√≥rico PERMANENTE\n",
    "    elif pais in stats_dict:\n",
    "        tipo_contexto = stats_dict[pais]['CATEGORIA']\n",
    "    else:\n",
    "        tipo_contexto = \"Muy_Bajo\"  # Pa√≠ses completamente nuevos\n",
    "    \n",
    "    return {\n",
    "        'score': score,\n",
    "        'umbral': umbral,\n",
    "        'es_anomalia': es_anomalia_final,\n",
    "        'tipo_contexto': tipo_contexto,\n",
    "        'razon_decision': razon,\n",
    "        'features': features\n",
    "    }\n",
    "\n",
    "print(\"üîÆ Funci√≥n de predicci√≥n mejorada definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ed55e1",
   "metadata": {},
   "source": [
    "# 11. SCORING EN PER√çODO DE PRUEBA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3107e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Scoring con modelo mejorado...\n",
      "   Scoring: 0/343910 registros\n",
      "   Scoring: 2000/343910 registros\n",
      "   Scoring: 4000/343910 registros\n",
      "   Scoring: 6000/343910 registros\n",
      "   Scoring: 8000/343910 registros\n",
      "   Scoring: 10000/343910 registros\n",
      "   Scoring: 12000/343910 registros\n",
      "   Scoring: 14000/343910 registros\n",
      "   Scoring: 16000/343910 registros\n",
      "   Scoring: 18000/343910 registros\n",
      "   Scoring: 20000/343910 registros\n",
      "   Scoring: 22000/343910 registros\n",
      "   Scoring: 24000/343910 registros\n",
      "   Scoring: 26000/343910 registros\n",
      "   Scoring: 28000/343910 registros\n",
      "   Scoring: 30000/343910 registros\n",
      "   Scoring: 32000/343910 registros\n",
      "   Scoring: 34000/343910 registros\n",
      "   Scoring: 36000/343910 registros\n",
      "   Scoring: 38000/343910 registros\n",
      "   Scoring: 40000/343910 registros\n",
      "   Scoring: 42000/343910 registros\n",
      "   Scoring: 44000/343910 registros\n",
      "   Scoring: 46000/343910 registros\n",
      "   Scoring: 48000/343910 registros\n",
      "   Scoring: 50000/343910 registros\n",
      "   Scoring: 52000/343910 registros\n",
      "   Scoring: 54000/343910 registros\n",
      "   Scoring: 56000/343910 registros\n",
      "   Scoring: 58000/343910 registros\n",
      "   Scoring: 60000/343910 registros\n",
      "   Scoring: 62000/343910 registros\n",
      "   Scoring: 64000/343910 registros\n",
      "   Scoring: 66000/343910 registros\n",
      "   Scoring: 68000/343910 registros\n",
      "   Scoring: 70000/343910 registros\n",
      "   Scoring: 72000/343910 registros\n",
      "   Scoring: 74000/343910 registros\n",
      "   Scoring: 76000/343910 registros\n",
      "   Scoring: 78000/343910 registros\n",
      "   Scoring: 80000/343910 registros\n",
      "   Scoring: 82000/343910 registros\n",
      "   Scoring: 84000/343910 registros\n",
      "   Scoring: 86000/343910 registros\n",
      "   Scoring: 88000/343910 registros\n",
      "   Scoring: 90000/343910 registros\n",
      "   Scoring: 92000/343910 registros\n",
      "   Scoring: 94000/343910 registros\n",
      "   Scoring: 96000/343910 registros\n",
      "   Scoring: 98000/343910 registros\n",
      "   Scoring: 100000/343910 registros\n",
      "   Scoring: 102000/343910 registros\n",
      "   Scoring: 104000/343910 registros\n",
      "   Scoring: 106000/343910 registros\n",
      "   Scoring: 108000/343910 registros\n",
      "   Scoring: 110000/343910 registros\n",
      "   Scoring: 112000/343910 registros\n",
      "   Scoring: 114000/343910 registros\n",
      "   Scoring: 116000/343910 registros\n",
      "   Scoring: 118000/343910 registros\n",
      "   Scoring: 120000/343910 registros\n",
      "   Scoring: 122000/343910 registros\n",
      "   Scoring: 124000/343910 registros\n",
      "   Scoring: 126000/343910 registros\n",
      "   Scoring: 128000/343910 registros\n",
      "   Scoring: 130000/343910 registros\n",
      "   Scoring: 132000/343910 registros\n",
      "   Scoring: 134000/343910 registros\n",
      "   Scoring: 136000/343910 registros\n",
      "   Scoring: 138000/343910 registros\n",
      "   Scoring: 140000/343910 registros\n",
      "   Scoring: 142000/343910 registros\n",
      "   Scoring: 144000/343910 registros\n",
      "   Scoring: 146000/343910 registros\n",
      "   Scoring: 148000/343910 registros\n",
      "   Scoring: 150000/343910 registros\n",
      "   Scoring: 152000/343910 registros\n",
      "   Scoring: 154000/343910 registros\n",
      "   Scoring: 156000/343910 registros\n",
      "   Scoring: 158000/343910 registros\n",
      "   Scoring: 160000/343910 registros\n",
      "   Scoring: 162000/343910 registros\n",
      "   Scoring: 164000/343910 registros\n",
      "   Scoring: 166000/343910 registros\n",
      "   Scoring: 168000/343910 registros\n",
      "   Scoring: 170000/343910 registros\n",
      "   Scoring: 172000/343910 registros\n",
      "   Scoring: 174000/343910 registros\n",
      "   Scoring: 176000/343910 registros\n",
      "   Scoring: 178000/343910 registros\n",
      "   Scoring: 180000/343910 registros\n",
      "   Scoring: 182000/343910 registros\n",
      "   Scoring: 184000/343910 registros\n",
      "   Scoring: 186000/343910 registros\n",
      "   Scoring: 188000/343910 registros\n",
      "   Scoring: 190000/343910 registros\n",
      "   Scoring: 192000/343910 registros\n",
      "   Scoring: 194000/343910 registros\n",
      "   Scoring: 196000/343910 registros\n",
      "   Scoring: 198000/343910 registros\n",
      "   Scoring: 200000/343910 registros\n",
      "   Scoring: 202000/343910 registros\n",
      "   Scoring: 204000/343910 registros\n",
      "   Scoring: 206000/343910 registros\n",
      "   Scoring: 208000/343910 registros\n",
      "   Scoring: 210000/343910 registros\n",
      "   Scoring: 212000/343910 registros\n",
      "   Scoring: 214000/343910 registros\n",
      "   Scoring: 216000/343910 registros\n",
      "   Scoring: 218000/343910 registros\n",
      "   Scoring: 220000/343910 registros\n",
      "   Scoring: 222000/343910 registros\n",
      "   Scoring: 224000/343910 registros\n",
      "   Scoring: 226000/343910 registros\n",
      "   Scoring: 228000/343910 registros\n",
      "   Scoring: 230000/343910 registros\n",
      "   Scoring: 232000/343910 registros\n",
      "   Scoring: 234000/343910 registros\n",
      "   Scoring: 236000/343910 registros\n",
      "   Scoring: 238000/343910 registros\n",
      "   Scoring: 240000/343910 registros\n",
      "   Scoring: 242000/343910 registros\n",
      "   Scoring: 244000/343910 registros\n",
      "   Scoring: 246000/343910 registros\n",
      "   Scoring: 248000/343910 registros\n",
      "   Scoring: 250000/343910 registros\n",
      "   Scoring: 252000/343910 registros\n",
      "   Scoring: 254000/343910 registros\n",
      "   Scoring: 256000/343910 registros\n",
      "   Scoring: 258000/343910 registros\n",
      "   Scoring: 260000/343910 registros\n",
      "   Scoring: 262000/343910 registros\n",
      "   Scoring: 264000/343910 registros\n",
      "   Scoring: 266000/343910 registros\n",
      "   Scoring: 268000/343910 registros\n",
      "   Scoring: 270000/343910 registros\n",
      "   Scoring: 272000/343910 registros\n",
      "   Scoring: 274000/343910 registros\n",
      "   Scoring: 276000/343910 registros\n",
      "   Scoring: 278000/343910 registros\n",
      "   Scoring: 280000/343910 registros\n",
      "   Scoring: 282000/343910 registros\n",
      "   Scoring: 284000/343910 registros\n",
      "   Scoring: 286000/343910 registros\n",
      "   Scoring: 288000/343910 registros\n",
      "   Scoring: 290000/343910 registros\n",
      "   Scoring: 292000/343910 registros\n",
      "   Scoring: 294000/343910 registros\n",
      "   Scoring: 296000/343910 registros\n",
      "   Scoring: 298000/343910 registros\n",
      "   Scoring: 300000/343910 registros\n",
      "   Scoring: 302000/343910 registros\n",
      "   Scoring: 304000/343910 registros\n",
      "   Scoring: 306000/343910 registros\n",
      "   Scoring: 308000/343910 registros\n",
      "   Scoring: 310000/343910 registros\n",
      "   Scoring: 312000/343910 registros\n",
      "   Scoring: 314000/343910 registros\n",
      "   Scoring: 316000/343910 registros\n",
      "   Scoring: 318000/343910 registros\n",
      "   Scoring: 320000/343910 registros\n",
      "   Scoring: 322000/343910 registros\n",
      "   Scoring: 324000/343910 registros\n",
      "   Scoring: 326000/343910 registros\n",
      "   Scoring: 328000/343910 registros\n",
      "   Scoring: 330000/343910 registros\n",
      "   Scoring: 332000/343910 registros\n",
      "   Scoring: 334000/343910 registros\n",
      "   Scoring: 336000/343910 registros\n",
      "   Scoring: 338000/343910 registros\n",
      "   Scoring: 340000/343910 registros\n",
      "   Scoring: 342000/343910 registros\n",
      "‚úÖ Scoring mejorado completado\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüéØ Scoring con modelo mejorado...\")\n",
    "\n",
    "resultados_mejorados = []\n",
    "\n",
    "for contador, (idx, row) in enumerate(df_scoring.iterrows()):\n",
    "    if contador % 2000 == 0:\n",
    "        print(f\"   Scoring: {contador}/{len(df_scoring)} registros\")\n",
    "    \n",
    "    resultado = predecir_anomalia_mejorada(\n",
    "        pais=row['CODIGODEPAIS'],\n",
    "        linea=row['LINEA'],\n",
    "        llamadas=row['N_LLAMADAS'],\n",
    "        minutos=row['N_MINUTOS'],\n",
    "        destinos=row['N_DESTINOS'],\n",
    "        modelo=modelo_mejorado,\n",
    "        scaler=scaler_mejorado,\n",
    "        umbral=umbral_objetivo,\n",
    "        stats_dict=stats_dict,\n",
    "        contexto_historico=config_general['contexto_historico']  # NUEVO\n",
    "    )\n",
    "    \n",
    "    resultado_completo = {\n",
    "        'FECHA': row['FECHA'],\n",
    "        'CODIGODEPAIS': row['CODIGODEPAIS'],\n",
    "        'LINEA': row['LINEA'],\n",
    "        'N_LLAMADAS': row['N_LLAMADAS'],\n",
    "        'N_MINUTOS': row['N_MINUTOS'],\n",
    "        'N_DESTINOS': row['N_DESTINOS'],\n",
    "        'score_anomalia': resultado['score'],\n",
    "        'umbral': resultado['umbral'],\n",
    "        'es_anomalia': resultado['es_anomalia'],\n",
    "        'tipo_contexto': resultado['tipo_contexto'],\n",
    "        'razon_decision': resultado['razon_decision']\n",
    "    }\n",
    "    \n",
    "    resultados_mejorados.append(resultado_completo)\n",
    "\n",
    "df_resultados_mejorados = pd.DataFrame(resultados_mejorados)\n",
    "\n",
    "print(\"‚úÖ Scoring mejorado completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc821f58",
   "metadata": {},
   "source": [
    "# 12. AN√ÅLISIS DETALLADO DE RESULTADOS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffc8011e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä RESULTADOS CON MODELO MEJORADO:\n",
      "üìû Total de l√≠neas evaluadas: 343910\n",
      "üö® Anomal√≠as detectadas: 2507\n",
      "üìà Tasa de anomal√≠as: 0.729%\n",
      "\n",
      "üîç RAZONES DE DECISIONES:\n",
      "razon_decision\n",
      "Score bajo umbral                         341175\n",
      "Patr√≥n de spray calling confirmado          2378\n",
      "No cumple criterios de confirmaci√≥n          127\n",
      "Actividad baja en pa√≠s de bajo tr√°fico        98\n",
      "Ratio destinos/llamadas muy bajo               3\n",
      "                                           ...  \n",
      "Minutos extremos (597.6 min)                   1\n",
      "Minutos extremos (558.3 min)                   1\n",
      "Minutos extremos (518.3 min)                   1\n",
      "Minutos extremos (419.6 min)                   1\n",
      "Minutos extremos (350.1 min)                   1\n",
      "Name: count, Length: 129, dtype: int64\n",
      "\n",
      "üéØ ANOMAL√çAS CONFIRMADAS (Top 10):\n",
      "        CODIGODEPAIS        LINEA  N_LLAMADAS  N_MINUTOS  N_DESTINOS  \\\n",
      "70256            593  51880609481         327     726.00         308   \n",
      "76478            593  51880609481         283     829.47         272   \n",
      "241913           593  51880609481         253     305.33         245   \n",
      "234282           593  51864259326         153     334.87         150   \n",
      "103488           593  51856106975         227     344.20         222   \n",
      "259450           593  51880609481         277     423.20         271   \n",
      "103362           593  51880609481         275     579.30         271   \n",
      "102180           593  51880609481         257     495.98         252   \n",
      "221213           593  51854856835         371     571.94         360   \n",
      "226937           593  51801304879         396     548.95         377   \n",
      "\n",
      "        score_anomalia                razon_decision  \n",
      "70256          0.99843  Minutos extremos (726.0 min)  \n",
      "76478          0.99843  Minutos extremos (829.5 min)  \n",
      "241913         0.99843  Minutos extremos (305.3 min)  \n",
      "234282         0.99843  Minutos extremos (334.9 min)  \n",
      "103488         0.99843  Minutos extremos (344.2 min)  \n",
      "259450         0.99843  Minutos extremos (423.2 min)  \n",
      "103362         0.99843  Minutos extremos (579.3 min)  \n",
      "102180         0.99843  Minutos extremos (496.0 min)  \n",
      "221213         0.99843  Minutos extremos (571.9 min)  \n",
      "226937         0.99843  Minutos extremos (549.0 min)  \n",
      "\n",
      "üìä ESTAD√çSTICAS DE ANOMAL√çAS CONFIRMADAS:\n",
      "üìû Llamadas - Min: 2, Max: 462, Media: 45.2\n",
      "üéØ Destinos - Min: 1, Max: 438, Media: 42.7\n",
      "‚è±Ô∏è Minutos - Min: 0.71, Max: 829.47, Media: 88.1\n",
      "üìä Ratio Destinos/Llamadas promedio: 0.917\n",
      "\n",
      "‚ö° DETECCIONES POR MINUTOS EXTREMOS: 124\n",
      "‚è±Ô∏è Minutos promedio en extremos: 466.0\n",
      "\n",
      "‚úÖ MEJORAS IMPLEMENTADAS:\n",
      "üîß Detecci√≥n inteligente de minutos extremos (‚â•300 min)\n",
      "üåç Pa√≠ses nuevos clasificados como 'Muy_Bajo' autom√°ticamente\n",
      "üìä Umbral configurable (P99 √ó 1.0)\n",
      "üõ°Ô∏è Reglas mejoradas anti-falsos positivos\n",
      "üéØ Mayor sensibilidad para pa√≠ses de bajo tr√°fico\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüìä RESULTADOS CON MODELO MEJORADO:\")\n",
    "print(f\"üìû Total de l√≠neas evaluadas: {len(df_resultados_mejorados)}\")\n",
    "print(f\"üö® Anomal√≠as detectadas: {df_resultados_mejorados['es_anomalia'].sum()}\")\n",
    "print(f\"üìà Tasa de anomal√≠as: {df_resultados_mejorados['es_anomalia'].mean()*100:.3f}%\")\n",
    "\n",
    "# An√°lisis de razones de decisi√≥n\n",
    "print(f\"\\nüîç RAZONES DE DECISIONES:\")\n",
    "razones = df_resultados_mejorados['razon_decision'].value_counts()\n",
    "print(razones)\n",
    "\n",
    "# Anomal√≠as confirmadas\n",
    "anomalias_confirmadas = df_resultados_mejorados[df_resultados_mejorados['es_anomalia'] == True]\n",
    "if len(anomalias_confirmadas) > 0:\n",
    "    print(f\"\\nüéØ ANOMAL√çAS CONFIRMADAS (Top 10):\")\n",
    "    print(anomalias_confirmadas.sort_values('score_anomalia', ascending=False)[\n",
    "        ['CODIGODEPAIS', 'LINEA', 'N_LLAMADAS', 'N_MINUTOS', 'N_DESTINOS', \n",
    "         'score_anomalia', 'razon_decision']\n",
    "    ].head(10))\n",
    "    \n",
    "    # Estad√≠sticas de anomal√≠as confirmadas\n",
    "    print(f\"\\nüìä ESTAD√çSTICAS DE ANOMAL√çAS CONFIRMADAS:\")\n",
    "    print(f\"üìû Llamadas - Min: {anomalias_confirmadas['N_LLAMADAS'].min()}, Max: {anomalias_confirmadas['N_LLAMADAS'].max()}, Media: {anomalias_confirmadas['N_LLAMADAS'].mean():.1f}\")\n",
    "    print(f\"üéØ Destinos - Min: {anomalias_confirmadas['N_DESTINOS'].min()}, Max: {anomalias_confirmadas['N_DESTINOS'].max()}, Media: {anomalias_confirmadas['N_DESTINOS'].mean():.1f}\")\n",
    "    print(f\"‚è±Ô∏è Minutos - Min: {anomalias_confirmadas['N_MINUTOS'].min()}, Max: {anomalias_confirmadas['N_MINUTOS'].max()}, Media: {anomalias_confirmadas['N_MINUTOS'].mean():.1f}\")\n",
    "    print(f\"üìä Ratio Destinos/Llamadas promedio: {(anomalias_confirmadas['N_DESTINOS']/anomalias_confirmadas['N_LLAMADAS']).mean():.3f}\")\n",
    "    \n",
    "    # An√°lisis de minutos extremos\n",
    "    minutos_extremos = anomalias_confirmadas[anomalias_confirmadas['razon_decision'].str.contains('Minutos extremos')]\n",
    "    if len(minutos_extremos) > 0:\n",
    "        print(f\"\\n‚ö° DETECCIONES POR MINUTOS EXTREMOS: {len(minutos_extremos)}\")\n",
    "        print(f\"‚è±Ô∏è Minutos promedio en extremos: {minutos_extremos['N_MINUTOS'].mean():.1f}\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No se detectaron anomal√≠as\")\n",
    "\n",
    "print(f\"\\n‚úÖ MEJORAS IMPLEMENTADAS:\")\n",
    "print(f\"üîß Detecci√≥n inteligente de minutos extremos (‚â•{UMBRAL_MINUTOS_EXTREMOS} min)\")\n",
    "print(f\"üåç Pa√≠ses nuevos clasificados como 'Muy_Bajo' autom√°ticamente\")\n",
    "print(f\"üìä Umbral configurable (P{PERCENTIL_BASE} √ó {AJUSTE_UMBRAL})\")\n",
    "print(f\"üõ°Ô∏è Reglas mejoradas anti-falsos positivos\")\n",
    "print(f\"üéØ Mayor sensibilidad para pa√≠ses de bajo tr√°fico\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a672f75b",
   "metadata": {},
   "source": [
    "# 13. GUARDAR RESULTADOS FINALES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b8c7f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üö® Solo anomal√≠as: C:\\Users\\User\\Desktop\\TESIS\\CodigoGithub\\MLTallerProyecto1\\Resultados\\anomalias_modelo_general.csv\n",
      "\n",
      "üíæ RESULTADOS GUARDADOS:\n",
      "üìÑ Todos los resultados: C:\\Users\\User\\Desktop\\TESIS\\CodigoGithub\\MLTallerProyecto1\\Resultados\\resultados_modelo_general.csv\n"
     ]
    }
   ],
   "source": [
    "# Guardar todos los resultados\n",
    "resultados_path = os.path.join(RESULTADO, \"resultados_modelo_general.csv\")\n",
    "df_resultados_mejorados.to_csv(resultados_path, index=False)\n",
    "\n",
    "# Guardar solo anomal√≠as si existen\n",
    "if len(anomalias_confirmadas) > 0:\n",
    "    anomalias_path = os.path.join(RESULTADO, \"anomalias_modelo_general.csv\")\n",
    "    anomalias_confirmadas.to_csv(anomalias_path, index=False)\n",
    "    print(f\"üö® Solo anomal√≠as: {anomalias_path}\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No hay anomal√≠as para guardar por separado\")\n",
    "\n",
    "print(f\"\\nüíæ RESULTADOS GUARDADOS:\")\n",
    "print(f\"üìÑ Todos los resultados: {resultados_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
