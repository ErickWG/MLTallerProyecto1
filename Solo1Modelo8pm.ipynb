{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80125b9c",
   "metadata": {},
   "source": [
    "# 1. IMPORTAR LIBRER√çAS NECESARIAS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd61c903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Librer√≠as importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from river import anomaly\n",
    "from river import preprocessing\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1132558",
   "metadata": {},
   "source": [
    "# 2. CONFIGURACI√ìN INICIAL Y PAR√ÅMETROS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1088d097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Directorio de modelos: C:\\Users\\User\\Desktop\\TESIS\\Modelos\n",
      "ü§ñ Modelo general con 80 √°rboles, altura 10\n",
      "‚öôÔ∏è Par√°metros configurables definidos\n"
     ]
    }
   ],
   "source": [
    "# Rutas de archivos\n",
    "DATASET_PATH = r\"C:\\Users\\User\\Desktop\\TESIS\\Datasets\\DataSetAgrupadoNoSuper3.csv\"\n",
    "MODELS_PATH = r\"C:\\Users\\User\\Desktop\\TESIS\\Modelos\"\n",
    "\n",
    "# Crear directorio de modelos si no existe\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "\n",
    "# PAR√ÅMETROS AJUSTABLES DEL MODELO ‚öôÔ∏è\n",
    "N_TREES = 80  # üîß AJUSTABLE: 60-120 (m√°s √°rboles = m√°s precisi√≥n pero m√°s lento)\n",
    "TREE_HEIGHT = 10  # üîß AJUSTABLE: 8-15 (mayor altura = patrones m√°s complejos)\n",
    "MIN_RECORDS_WARMUP = 50  # M√≠nimo de registros para warm-up por pa√≠s\n",
    "\n",
    "# PAR√ÅMETROS DE FEATURES ‚öôÔ∏è\n",
    "PESO_MINUTOS_NORMAL = 0.4  # üîß AJUSTABLE: 0.2-0.6 (peso normal de minutos)\n",
    "PESO_MINUTOS_EXTREMOS = 1.5  # üîß AJUSTABLE: 1.2-2.0 (peso cuando minutos son extremos)\n",
    "UMBRAL_MINUTOS_EXTREMOS = 300  # üîß AJUSTABLE: 200-500 (minutos para considerar extremo)\n",
    "PESO_DESTINOS = 1.2  # üîß AJUSTABLE: 1.0-1.5 (importancia de destinos)\n",
    "PESO_SPRAY_RATIO = 1.5  # üîß AJUSTABLE: 1.2-2.0 (importancia del ratio spray)\n",
    "\n",
    "# PAR√ÅMETROS DE UMBRAL ‚öôÔ∏è\n",
    "PERCENTIL_BASE = 99  # üîß AJUSTABLE: 95-99.5 (percentil para umbral)\n",
    "AJUSTE_UMBRAL = 1.0  # üîß AJUSTABLE: 0.8-1.2 (multiplicador del umbral)\n",
    "\n",
    "print(f\"üìÅ Directorio de modelos: {MODELS_PATH}\")\n",
    "print(f\"ü§ñ Modelo general con {N_TREES} √°rboles, altura {TREE_HEIGHT}\")\n",
    "print(f\"‚öôÔ∏è Par√°metros configurables definidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d093646b",
   "metadata": {},
   "source": [
    "# 3. CARGAR Y EXPLORAR EL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9074fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Cargando dataset...\n",
      "üìã Dataset cargado - Shape: (794810, 6)\n",
      "üìÖ Rango de fechas: 2025-03-01 00:00:00 a 2025-04-24 00:00:00\n",
      "üåç Pa√≠ses √∫nicos: 188\n",
      "üìû L√≠neas √∫nicas: 458606\n",
      "\n",
      "üìä Estad√≠sticas generales:\n",
      "üìû Llamadas - Min: 1, Max: 579, Media: 1.9\n",
      "‚è±Ô∏è Minutos - Min: 0.02, Max: 1019.8, Media: 5.8\n",
      "üéØ Destinos - Min: 1, Max: 546, Media: 1.7\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîÑ Cargando dataset...\")\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "\n",
    "# Convertir fecha a datetime\n",
    "df['FECHA'] = pd.to_datetime(df['FECHA'], format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "print(f\"üìã Dataset cargado - Shape: {df.shape}\")\n",
    "print(f\"üìÖ Rango de fechas: {df['FECHA'].min()} a {df['FECHA'].max()}\")\n",
    "print(f\"üåç Pa√≠ses √∫nicos: {df['CODIGODEPAIS'].nunique()}\")\n",
    "print(f\"üìû L√≠neas √∫nicas: {df['LINEA'].nunique()}\")\n",
    "\n",
    "# Mostrar estad√≠sticas generales\n",
    "print(f\"\\nüìä Estad√≠sticas generales:\")\n",
    "print(f\"üìû Llamadas - Min: {df['N_LLAMADAS'].min()}, Max: {df['N_LLAMADAS'].max()}, Media: {df['N_LLAMADAS'].mean():.1f}\")\n",
    "print(f\"‚è±Ô∏è Minutos - Min: {df['N_MINUTOS'].min()}, Max: {df['N_MINUTOS'].max()}, Media: {df['N_MINUTOS'].mean():.1f}\")\n",
    "print(f\"üéØ Destinos - Min: {df['N_DESTINOS'].min()}, Max: {df['N_DESTINOS'].max()}, Media: {df['N_DESTINOS'].mean():.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e496af9",
   "metadata": {},
   "source": [
    "# 4. DIVISI√ìN TEMPORAL PARA WARM-UP Y SCORING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2624add5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÜ Per√≠odo de warm-up: 2025-03\n",
      "üìÜ Per√≠odo de scoring: 2025-04\n",
      "üî¢ Registros warm-up: 450900\n",
      "üî¢ Registros scoring: 343910\n"
     ]
    }
   ],
   "source": [
    "df_sorted = df.sort_values('FECHA')\n",
    "fechas_unicas = sorted(df['FECHA'].dt.to_period('M').unique())\n",
    "\n",
    "if len(fechas_unicas) >= 2:\n",
    "    primer_mes = fechas_unicas[0]\n",
    "    segundo_mes = fechas_unicas[1]\n",
    "    \n",
    "    df_warmup = df[df['FECHA'].dt.to_period('M') == primer_mes].copy()\n",
    "    df_scoring = df[df['FECHA'].dt.to_period('M') == segundo_mes].copy()\n",
    "    \n",
    "    print(f\"\\nüìÜ Per√≠odo de warm-up: {primer_mes}\")\n",
    "    print(f\"üìÜ Per√≠odo de scoring: {segundo_mes}\")\n",
    "else:\n",
    "    # Divisi√≥n por mediana de fechas\n",
    "    fecha_corte = df_sorted['FECHA'].quantile(0.5)\n",
    "    df_warmup = df[df['FECHA'] <= fecha_corte].copy()\n",
    "    df_scoring = df[df['FECHA'] > fecha_corte].copy()\n",
    "    \n",
    "    print(f\"\\nüìÜ Divisi√≥n por fecha de corte: {fecha_corte}\")\n",
    "\n",
    "print(f\"üî¢ Registros warm-up: {len(df_warmup)}\")\n",
    "print(f\"üî¢ Registros scoring: {len(df_scoring)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290147ff",
   "metadata": {},
   "source": [
    "# 5. AN√ÅLISIS DE CONTEXTO POR PA√çS (PARA NORMALIZACI√ìN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7d1410a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üåç Analizando contexto por pa√≠s...\n",
      "üìä Distribuci√≥n de pa√≠ses por tr√°fico:\n",
      "CATEGORIA\n",
      "Muy_Bajo    129\n",
      "Bajo         21\n",
      "Medio        20\n",
      "Alto         18\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üîç Ejemplos por categor√≠a de tr√°fico:\n",
      "\n",
      "Muy_Bajo (129 pa√≠ses):\n",
      "              REGISTROS  LLAMADAS_MEAN  DESTINOS_MEAN  MINUTOS_MEAN\n",
      "CODIGODEPAIS                                                       \n",
      "27                   26           1.27           1.15          0.40\n",
      "40                   24           1.38           1.00          0.40\n",
      "62                   29           1.07           1.07          0.14\n",
      "\n",
      "Bajo (21 pa√≠ses):\n",
      "              REGISTROS  LLAMADAS_MEAN  DESTINOS_MEAN  MINUTOS_MEAN\n",
      "CODIGODEPAIS                                                       \n",
      "20                   81           1.22           1.01          0.18\n",
      "30                   98           1.37           1.16          2.35\n",
      "36                  120           1.23           1.02          0.10\n",
      "\n",
      "Medio (20 pa√≠ses):\n",
      "              REGISTROS  LLAMADAS_MEAN  DESTINOS_MEAN  MINUTOS_MEAN\n",
      "CODIGODEPAIS                                                       \n",
      "31                  313           1.59           1.06          3.75\n",
      "32                  216           1.37           1.06          1.36\n",
      "41                  364           1.25           1.06          3.48\n",
      "\n",
      "Alto (18 pa√≠ses):\n",
      "              REGISTROS  LLAMADAS_MEAN  DESTINOS_MEAN  MINUTOS_MEAN\n",
      "CODIGODEPAIS                                                       \n",
      "1                 82438           2.01           1.20         11.71\n",
      "7                  3653           1.17           1.06          0.22\n",
      "33                 1130           2.15           1.11          2.32\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüåç Analizando contexto por pa√≠s...\")\n",
    "\n",
    "# Calcular estad√≠sticas por pa√≠s en per√≠odo de warm-up\n",
    "stats_por_pais = df_warmup.groupby('CODIGODEPAIS').agg({\n",
    "    'N_LLAMADAS': ['count', 'mean', 'std', lambda x: x.quantile(0.90), lambda x: x.quantile(0.95)],\n",
    "    'N_MINUTOS': ['mean', 'std', lambda x: x.quantile(0.90), lambda x: x.quantile(0.95)],\n",
    "    'N_DESTINOS': ['mean', 'std', lambda x: x.quantile(0.90), lambda x: x.quantile(0.95)]\n",
    "}).round(2)\n",
    "\n",
    "stats_por_pais.columns = ['REGISTROS', 'LLAMADAS_MEAN', 'LLAMADAS_STD', 'LLAMADAS_P90', 'LLAMADAS_P95',\n",
    "                         'MINUTOS_MEAN', 'MINUTOS_STD', 'MINUTOS_P90', 'MINUTOS_P95',\n",
    "                         'DESTINOS_MEAN', 'DESTINOS_STD', 'DESTINOS_P90', 'DESTINOS_P95']\n",
    "\n",
    "# Clasificar pa√≠ses por volumen de tr√°fico\n",
    "stats_por_pais['CATEGORIA'] = pd.cut(stats_por_pais['REGISTROS'], \n",
    "                                   bins=[0, 50, 200, 1000, float('inf')],\n",
    "                                   labels=['Muy_Bajo', 'Bajo', 'Medio', 'Alto'])\n",
    "\n",
    "print(f\"üìä Distribuci√≥n de pa√≠ses por tr√°fico:\")\n",
    "print(stats_por_pais['CATEGORIA'].value_counts())\n",
    "\n",
    "# Mostrar ejemplos por categor√≠a\n",
    "print(f\"\\nüîç Ejemplos por categor√≠a de tr√°fico:\")\n",
    "for categoria in ['Muy_Bajo', 'Bajo', 'Medio', 'Alto']:\n",
    "    paises_cat = stats_por_pais[stats_por_pais['CATEGORIA'] == categoria]\n",
    "    if len(paises_cat) > 0:\n",
    "        print(f\"\\n{categoria} ({len(paises_cat)} pa√≠ses):\")\n",
    "        print(paises_cat[['REGISTROS', 'LLAMADAS_MEAN', 'DESTINOS_MEAN', 'MINUTOS_MEAN']].head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bb3c62",
   "metadata": {},
   "source": [
    "# 6. FUNCI√ìN PARA CREAR CARACTER√çSTICAS CONTEXTUALIZADAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3780762c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Funci√≥n de features mejorada definida (detecci√≥n de minutos extremos)\n"
     ]
    }
   ],
   "source": [
    "def crear_features_contextualizadas_mejorada(row, stats_pais_dict):\n",
    "    \"\"\"\n",
    "    Crea caracter√≠sticas balanceadas que detecten minutos extremos y spray calling\n",
    "    \"\"\"\n",
    "    pais = row['CODIGODEPAIS']\n",
    "    llamadas = row['N_LLAMADAS']\n",
    "    minutos = row['N_MINUTOS']\n",
    "    destinos = row['N_DESTINOS']\n",
    "    \n",
    "    # Obtener contexto del pa√≠s (si existe)\n",
    "    if pais in stats_pais_dict:\n",
    "        pais_stats = stats_pais_dict[pais]\n",
    "        categoria = pais_stats['CATEGORIA']\n",
    "        \n",
    "        # Normalizar por el contexto del pa√≠s\n",
    "        llamadas_norm = min(llamadas / max(pais_stats['LLAMADAS_P95'], 1), 1.5)\n",
    "        destinos_norm = min(destinos / max(pais_stats['DESTINOS_P95'], 1), 1.5)\n",
    "        \n",
    "        # MEJORA: Detecci√≥n inteligente de minutos extremos\n",
    "        minutos_p90 = pais_stats.get('MINUTOS_P90', pais_stats['MINUTOS_P95'] * 0.9)\n",
    "        minutos_p95 = pais_stats['MINUTOS_P95']\n",
    "        \n",
    "        # Transformaci√≥n adaptativa de minutos\n",
    "        if minutos >= UMBRAL_MINUTOS_EXTREMOS:  # üîß Minutos extremos\n",
    "            minutos_norm = min(minutos / max(minutos_p90, 1), 3.0)  # Mayor rango para extremos\n",
    "            peso_minutos = PESO_MINUTOS_EXTREMOS  # Peso alto para extremos\n",
    "        else:\n",
    "            minutos_norm = min(np.log1p(minutos) / np.log1p(max(minutos_p90, 1)), 1.2)\n",
    "            peso_minutos = PESO_MINUTOS_NORMAL  # Peso normal\n",
    "            \n",
    "    else:\n",
    "        # Pa√≠s nuevo - SIEMPRE clasificar como 'Muy_Bajo'\n",
    "        categoria = 'Muy_Bajo'\n",
    "        llamadas_norm = min(llamadas / 10, 2.0)  # M√°s sensible para pa√≠ses nuevos\n",
    "        destinos_norm = min(destinos / 5, 2.0)   # M√°s sensible para pa√≠ses nuevos\n",
    "        \n",
    "        # Para pa√≠ses nuevos, ser m√°s sensible a minutos altos\n",
    "        if minutos >= UMBRAL_MINUTOS_EXTREMOS:\n",
    "            minutos_norm = min(minutos / 50, 3.0)  # Muy sensible a minutos extremos\n",
    "            peso_minutos = PESO_MINUTOS_EXTREMOS * 1.2  # Peso extra para pa√≠ses nuevos\n",
    "        else:\n",
    "            minutos_norm = min(np.log1p(minutos) / np.log1p(60), 1.2)\n",
    "            peso_minutos = PESO_MINUTOS_NORMAL\n",
    "    \n",
    "    # Features principales - REBALANCEADAS con detecci√≥n de extremos\n",
    "    features = {\n",
    "        # 1. Valores normalizados con peso adaptativo\n",
    "        'llamadas_norm': llamadas_norm * 0.8,\n",
    "        'destinos_norm': destinos_norm * PESO_DESTINOS,  # üîß Ajustable\n",
    "        'minutos_norm': minutos_norm * peso_minutos,     # üîß Peso adaptativo\n",
    "        \n",
    "        # 2. Ratios cr√≠ticos para fraude\n",
    "        'diversidad_destinos': min(destinos / max(llamadas, 1), 1.0),\n",
    "        'spray_ratio': min(destinos / max(llamadas, 1) * PESO_SPRAY_RATIO, 1.0) if destinos >= 5 else 0,\n",
    "        \n",
    "        # 3. NUEVA: Detecci√≥n espec√≠fica de minutos extremos\n",
    "        'minutos_extremos': 1.0 if minutos >= UMBRAL_MINUTOS_EXTREMOS else 0.0,\n",
    "        'minutos_sospechosos': min((minutos - 200) / 300, 1.0) if minutos > 200 else 0.0,\n",
    "        \n",
    "        # 4. Patrones de fraude\n",
    "        'patron_spray_fuerte': 1.0 if (destinos >= 10 and llamadas >= 20) else 0.0,\n",
    "        'patron_spray_medio': 0.5 if (destinos >= 6 and llamadas >= 12) else 0.0,\n",
    "        'alta_diversidad': min(destinos / 12, 1) if destinos >= 5 else 0,\n",
    "        \n",
    "        # 5. Indicadores de volumen an√≥malo\n",
    "        'volumen_llamadas_alto': min((llamadas - 30) / 50, 1) if llamadas > 30 else 0,\n",
    "        'volumen_destinos_alto': min((destinos - 10) / 20, 1) if destinos > 10 else 0,\n",
    "        \n",
    "        # 6. Caracter√≠sticas de comportamiento\n",
    "        'llamadas_por_destino': min(llamadas / max(destinos, 1) / 5, 1),\n",
    "        'eficiencia_destinos': min(destinos / max(llamadas * 0.5, 1), 1),\n",
    "        \n",
    "        # 7. MEJORA: Ajuste por contexto de pa√≠s\n",
    "        'factor_pais_bajo': 1.5 if categoria in ['Muy_Bajo', 'Bajo'] else 1.0,  # M√°s sensible\n",
    "        'factor_pais_alto': 0.9 if categoria in ['Alto', 'Medio'] else 1.0      # Menos sensible\n",
    "    }\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Convertir stats a diccionario para b√∫squeda r√°pida\n",
    "stats_dict = {}\n",
    "for pais, row in stats_por_pais.iterrows():\n",
    "    stats_dict[pais] = row.to_dict()\n",
    "\n",
    "print(\"üîß Funci√≥n de features mejorada definida (detecci√≥n de minutos extremos)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0fc5f7",
   "metadata": {},
   "source": [
    "# 7. ENTRENAMIENTO DEL MODELO GENERAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18ee7735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Entrenando modelo con detecci√≥n de extremos...\n",
      "üîÑ Procesando con features mejoradas...\n",
      "   Procesado: 0/450900 registros\n",
      "   Procesado: 2000/450900 registros\n",
      "   Procesado: 4000/450900 registros\n",
      "   Procesado: 6000/450900 registros\n",
      "   Procesado: 8000/450900 registros\n",
      "   Procesado: 10000/450900 registros\n",
      "   Procesado: 12000/450900 registros\n",
      "   Procesado: 14000/450900 registros\n",
      "   Procesado: 16000/450900 registros\n",
      "   Procesado: 18000/450900 registros\n",
      "   Procesado: 20000/450900 registros\n",
      "   Procesado: 22000/450900 registros\n",
      "   Procesado: 24000/450900 registros\n",
      "   Procesado: 26000/450900 registros\n",
      "   Procesado: 28000/450900 registros\n",
      "   Procesado: 30000/450900 registros\n",
      "   Procesado: 32000/450900 registros\n",
      "   Procesado: 34000/450900 registros\n",
      "   Procesado: 36000/450900 registros\n",
      "   Procesado: 38000/450900 registros\n",
      "   Procesado: 40000/450900 registros\n",
      "   Procesado: 42000/450900 registros\n",
      "   Procesado: 44000/450900 registros\n",
      "   Procesado: 46000/450900 registros\n",
      "   Procesado: 48000/450900 registros\n",
      "   Procesado: 50000/450900 registros\n",
      "   Procesado: 52000/450900 registros\n",
      "   Procesado: 54000/450900 registros\n",
      "   Procesado: 56000/450900 registros\n",
      "   Procesado: 58000/450900 registros\n",
      "   Procesado: 60000/450900 registros\n",
      "   Procesado: 62000/450900 registros\n",
      "   Procesado: 64000/450900 registros\n",
      "   Procesado: 66000/450900 registros\n",
      "   Procesado: 68000/450900 registros\n",
      "   Procesado: 70000/450900 registros\n",
      "   Procesado: 72000/450900 registros\n",
      "   Procesado: 74000/450900 registros\n",
      "   Procesado: 76000/450900 registros\n",
      "   Procesado: 78000/450900 registros\n",
      "   Procesado: 80000/450900 registros\n",
      "   Procesado: 82000/450900 registros\n",
      "   Procesado: 84000/450900 registros\n",
      "   Procesado: 86000/450900 registros\n",
      "   Procesado: 88000/450900 registros\n",
      "   Procesado: 90000/450900 registros\n",
      "   Procesado: 92000/450900 registros\n",
      "   Procesado: 94000/450900 registros\n",
      "   Procesado: 96000/450900 registros\n",
      "   Procesado: 98000/450900 registros\n",
      "   Procesado: 100000/450900 registros\n",
      "   Procesado: 102000/450900 registros\n",
      "   Procesado: 104000/450900 registros\n",
      "   Procesado: 106000/450900 registros\n",
      "   Procesado: 108000/450900 registros\n",
      "   Procesado: 110000/450900 registros\n",
      "   Procesado: 112000/450900 registros\n",
      "   Procesado: 114000/450900 registros\n",
      "   Procesado: 116000/450900 registros\n",
      "   Procesado: 118000/450900 registros\n",
      "   Procesado: 120000/450900 registros\n",
      "   Procesado: 122000/450900 registros\n",
      "   Procesado: 124000/450900 registros\n",
      "   Procesado: 126000/450900 registros\n",
      "   Procesado: 128000/450900 registros\n",
      "   Procesado: 130000/450900 registros\n",
      "   Procesado: 132000/450900 registros\n",
      "   Procesado: 134000/450900 registros\n",
      "   Procesado: 136000/450900 registros\n",
      "   Procesado: 138000/450900 registros\n",
      "   Procesado: 140000/450900 registros\n",
      "   Procesado: 142000/450900 registros\n",
      "   Procesado: 144000/450900 registros\n",
      "   Procesado: 146000/450900 registros\n",
      "   Procesado: 148000/450900 registros\n",
      "   Procesado: 150000/450900 registros\n",
      "   Procesado: 152000/450900 registros\n",
      "   Procesado: 154000/450900 registros\n",
      "   Procesado: 156000/450900 registros\n",
      "   Procesado: 158000/450900 registros\n",
      "   Procesado: 160000/450900 registros\n",
      "   Procesado: 162000/450900 registros\n",
      "   Procesado: 164000/450900 registros\n",
      "   Procesado: 166000/450900 registros\n",
      "   Procesado: 168000/450900 registros\n",
      "   Procesado: 170000/450900 registros\n",
      "   Procesado: 172000/450900 registros\n",
      "   Procesado: 174000/450900 registros\n",
      "   Procesado: 176000/450900 registros\n",
      "   Procesado: 178000/450900 registros\n",
      "   Procesado: 180000/450900 registros\n",
      "   Procesado: 182000/450900 registros\n",
      "   Procesado: 184000/450900 registros\n",
      "   Procesado: 186000/450900 registros\n",
      "   Procesado: 188000/450900 registros\n",
      "   Procesado: 190000/450900 registros\n",
      "   Procesado: 192000/450900 registros\n",
      "   Procesado: 194000/450900 registros\n",
      "   Procesado: 196000/450900 registros\n",
      "   Procesado: 198000/450900 registros\n",
      "   Procesado: 200000/450900 registros\n",
      "   Procesado: 202000/450900 registros\n",
      "   Procesado: 204000/450900 registros\n",
      "   Procesado: 206000/450900 registros\n",
      "   Procesado: 208000/450900 registros\n",
      "   Procesado: 210000/450900 registros\n",
      "   Procesado: 212000/450900 registros\n",
      "   Procesado: 214000/450900 registros\n",
      "   Procesado: 216000/450900 registros\n",
      "   Procesado: 218000/450900 registros\n",
      "   Procesado: 220000/450900 registros\n",
      "   Procesado: 222000/450900 registros\n",
      "   Procesado: 224000/450900 registros\n",
      "   Procesado: 226000/450900 registros\n",
      "   Procesado: 228000/450900 registros\n",
      "   Procesado: 230000/450900 registros\n",
      "   Procesado: 232000/450900 registros\n",
      "   Procesado: 234000/450900 registros\n",
      "   Procesado: 236000/450900 registros\n",
      "   Procesado: 238000/450900 registros\n",
      "   Procesado: 240000/450900 registros\n",
      "   Procesado: 242000/450900 registros\n",
      "   Procesado: 244000/450900 registros\n",
      "   Procesado: 246000/450900 registros\n",
      "   Procesado: 248000/450900 registros\n",
      "   Procesado: 250000/450900 registros\n",
      "   Procesado: 252000/450900 registros\n",
      "   Procesado: 254000/450900 registros\n",
      "   Procesado: 256000/450900 registros\n",
      "   Procesado: 258000/450900 registros\n",
      "   Procesado: 260000/450900 registros\n",
      "   Procesado: 262000/450900 registros\n",
      "   Procesado: 264000/450900 registros\n",
      "   Procesado: 266000/450900 registros\n",
      "   Procesado: 268000/450900 registros\n",
      "   Procesado: 270000/450900 registros\n",
      "   Procesado: 272000/450900 registros\n",
      "   Procesado: 274000/450900 registros\n",
      "   Procesado: 276000/450900 registros\n",
      "   Procesado: 278000/450900 registros\n",
      "   Procesado: 280000/450900 registros\n",
      "   Procesado: 282000/450900 registros\n",
      "   Procesado: 284000/450900 registros\n",
      "   Procesado: 286000/450900 registros\n",
      "   Procesado: 288000/450900 registros\n",
      "   Procesado: 290000/450900 registros\n",
      "   Procesado: 292000/450900 registros\n",
      "   Procesado: 294000/450900 registros\n",
      "   Procesado: 296000/450900 registros\n",
      "   Procesado: 298000/450900 registros\n",
      "   Procesado: 300000/450900 registros\n",
      "   Procesado: 302000/450900 registros\n",
      "   Procesado: 304000/450900 registros\n",
      "   Procesado: 306000/450900 registros\n",
      "   Procesado: 308000/450900 registros\n",
      "   Procesado: 310000/450900 registros\n",
      "   Procesado: 312000/450900 registros\n",
      "   Procesado: 314000/450900 registros\n",
      "   Procesado: 316000/450900 registros\n",
      "   Procesado: 318000/450900 registros\n",
      "   Procesado: 320000/450900 registros\n",
      "   Procesado: 322000/450900 registros\n",
      "   Procesado: 324000/450900 registros\n",
      "   Procesado: 326000/450900 registros\n",
      "   Procesado: 328000/450900 registros\n",
      "   Procesado: 330000/450900 registros\n",
      "   Procesado: 332000/450900 registros\n",
      "   Procesado: 334000/450900 registros\n",
      "   Procesado: 336000/450900 registros\n",
      "   Procesado: 338000/450900 registros\n",
      "   Procesado: 340000/450900 registros\n",
      "   Procesado: 342000/450900 registros\n",
      "   Procesado: 344000/450900 registros\n",
      "   Procesado: 346000/450900 registros\n",
      "   Procesado: 348000/450900 registros\n",
      "   Procesado: 350000/450900 registros\n",
      "   Procesado: 352000/450900 registros\n",
      "   Procesado: 354000/450900 registros\n",
      "   Procesado: 356000/450900 registros\n",
      "   Procesado: 358000/450900 registros\n",
      "   Procesado: 360000/450900 registros\n",
      "   Procesado: 362000/450900 registros\n",
      "   Procesado: 364000/450900 registros\n",
      "   Procesado: 366000/450900 registros\n",
      "   Procesado: 368000/450900 registros\n",
      "   Procesado: 370000/450900 registros\n",
      "   Procesado: 372000/450900 registros\n",
      "   Procesado: 374000/450900 registros\n",
      "   Procesado: 376000/450900 registros\n",
      "   Procesado: 378000/450900 registros\n",
      "   Procesado: 380000/450900 registros\n",
      "   Procesado: 382000/450900 registros\n",
      "   Procesado: 384000/450900 registros\n",
      "   Procesado: 386000/450900 registros\n",
      "   Procesado: 388000/450900 registros\n",
      "   Procesado: 390000/450900 registros\n",
      "   Procesado: 392000/450900 registros\n",
      "   Procesado: 394000/450900 registros\n",
      "   Procesado: 396000/450900 registros\n",
      "   Procesado: 398000/450900 registros\n",
      "   Procesado: 400000/450900 registros\n",
      "   Procesado: 402000/450900 registros\n",
      "   Procesado: 404000/450900 registros\n",
      "   Procesado: 406000/450900 registros\n",
      "   Procesado: 408000/450900 registros\n",
      "   Procesado: 410000/450900 registros\n",
      "   Procesado: 412000/450900 registros\n",
      "   Procesado: 414000/450900 registros\n",
      "   Procesado: 416000/450900 registros\n",
      "   Procesado: 418000/450900 registros\n",
      "   Procesado: 420000/450900 registros\n",
      "   Procesado: 422000/450900 registros\n",
      "   Procesado: 424000/450900 registros\n",
      "   Procesado: 426000/450900 registros\n",
      "   Procesado: 428000/450900 registros\n",
      "   Procesado: 430000/450900 registros\n",
      "   Procesado: 432000/450900 registros\n",
      "   Procesado: 434000/450900 registros\n",
      "   Procesado: 436000/450900 registros\n",
      "   Procesado: 438000/450900 registros\n",
      "   Procesado: 440000/450900 registros\n",
      "   Procesado: 442000/450900 registros\n",
      "   Procesado: 444000/450900 registros\n",
      "   Procesado: 446000/450900 registros\n",
      "   Procesado: 448000/450900 registros\n",
      "   Procesado: 450000/450900 registros\n",
      "‚úÖ Entrenamiento completado\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nü§ñ Entrenando modelo con detecci√≥n de extremos...\")\n",
    "\n",
    "# Crear modelo con par√°metros configurables\n",
    "modelo_mejorado = anomaly.HalfSpaceTrees(\n",
    "    n_trees=N_TREES,\n",
    "    height=TREE_HEIGHT,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Crear scaler\n",
    "scaler_mejorado = preprocessing.StandardScaler()\n",
    "\n",
    "# Procesar datos con features mejoradas\n",
    "scores_mejorados = []\n",
    "features_mejoradas = []\n",
    "\n",
    "print(\"üîÑ Procesando con features mejoradas...\")\n",
    "for contador, (idx, row) in enumerate(df_warmup.iterrows()):\n",
    "    if contador % 2000 == 0:\n",
    "        print(f\"   Procesado: {contador}/{len(df_warmup)} registros\")\n",
    "    \n",
    "    # Usar funci√≥n mejorada\n",
    "    features = crear_features_contextualizadas_mejorada(row, stats_dict)\n",
    "    \n",
    "    # Normalizar\n",
    "    scaler_mejorado.learn_one(features)\n",
    "    features_scaled = scaler_mejorado.transform_one(features)\n",
    "    \n",
    "    # Score y entrenamiento\n",
    "    score = modelo_mejorado.score_one(features_scaled)\n",
    "    scores_mejorados.append(score)\n",
    "    features_mejoradas.append(features)\n",
    "    \n",
    "    modelo_mejorado.learn_one(features_scaled)\n",
    "\n",
    "print(\"‚úÖ Entrenamiento completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddd50b1",
   "metadata": {},
   "source": [
    "# 8. CALCULAR UMBRAL GLOBAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c851e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä AN√ÅLISIS DE UMBRALES POSIBLES:\n",
      "P90: Umbral=0.8191, Tasa=10.00%\n",
      "P92: Umbral=0.8479, Tasa=8.00%\n",
      "P94: Umbral=0.8840, Tasa=6.00%\n",
      "P95: Umbral=0.8990, Tasa=5.00%\n",
      "P96: Umbral=0.9115, Tasa=4.00%\n",
      "P97: Umbral=0.9233, Tasa=3.00%\n",
      "P98: Umbral=0.9417, Tasa=2.00%\n",
      "P99: Umbral=0.9724, Tasa=1.00%\n",
      "P99.5: Umbral=0.9967, Tasa=0.50%\n",
      "\n",
      "üéØ UMBRAL SELECCIONADO:\n",
      "üìä Percentil base: P99\n",
      "üî¢ Umbral final: 0.9724\n",
      "üìà Tasa estimada: 1.00%\n",
      "‚öôÔ∏è Ajuste aplicado: 1.0\n"
     ]
    }
   ],
   "source": [
    "# An√°lisis detallado de scores para encontrar umbral √≥ptimo\n",
    "scores_array = np.array(scores_mejorados)\n",
    "\n",
    "# Calcular m√∫ltiples percentiles\n",
    "percentiles = [90, 92, 94, 95, 96, 97, 98, 99, 99.5]\n",
    "umbrales = {}\n",
    "\n",
    "print(f\"\\nüìä AN√ÅLISIS DE UMBRALES POSIBLES:\")\n",
    "for p in percentiles:\n",
    "    umbral = np.percentile(scores_array, p)\n",
    "    tasa_anomalia = (scores_array > umbral).mean() * 100\n",
    "    umbrales[p] = {'umbral': umbral, 'tasa': tasa_anomalia}\n",
    "    print(f\"P{p}: Umbral={umbral:.4f}, Tasa={tasa_anomalia:.2f}%\")\n",
    "\n",
    "# Seleccionar umbral basado en PERCENTIL_BASE configurado\n",
    "umbral_base = umbrales[PERCENTIL_BASE]['umbral']\n",
    "umbral_objetivo = umbral_base * AJUSTE_UMBRAL  # üîß Ajuste configurable\n",
    "\n",
    "# Calcular tasa final\n",
    "tasa_objetivo = (scores_array > umbral_objetivo).mean() * 100\n",
    "\n",
    "print(f\"\\nüéØ UMBRAL SELECCIONADO:\")\n",
    "print(f\"üìä Percentil base: P{PERCENTIL_BASE}\")\n",
    "print(f\"üî¢ Umbral final: {umbral_objetivo:.4f}\")\n",
    "print(f\"üìà Tasa estimada: {tasa_objetivo:.2f}%\")\n",
    "print(f\"‚öôÔ∏è Ajuste aplicado: {AJUSTE_UMBRAL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c6265f",
   "metadata": {},
   "source": [
    "# 9. GUARDAR MODELO Y CONFIGURACI√ìN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0852dd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Guardando modelo mejorado...\n",
      "‚úÖ Modelo mejorado guardado exitosamente\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüíæ Guardando modelo mejorado...\")\n",
    "\n",
    "# Guardar modelo\n",
    "modelo_path = os.path.join(MODELS_PATH, \"modelo_general.pkl\")\n",
    "with open(modelo_path, 'wb') as f:\n",
    "    pickle.dump(modelo_mejorado, f)\n",
    "\n",
    "# Guardar scaler\n",
    "scaler_path = os.path.join(MODELS_PATH, \"scaler_general.pkl\")\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler_mejorado, f)\n",
    "\n",
    "# Guardar configuraci√≥n\n",
    "config_general = {\n",
    "    'umbral_global': umbral_objetivo,\n",
    "    'stats_por_pais': stats_dict,\n",
    "    'fecha_entrenamiento': datetime.now().isoformat(),\n",
    "    'n_trees': N_TREES,\n",
    "    'tree_height': TREE_HEIGHT,\n",
    "    'registros_entrenamiento': len(df_warmup),\n",
    "    'paises_entrenamiento': df_warmup['CODIGODEPAIS'].nunique(),\n",
    "    'parametros_features': {\n",
    "        'peso_minutos_normal': PESO_MINUTOS_NORMAL,\n",
    "        'peso_minutos_extremos': PESO_MINUTOS_EXTREMOS,\n",
    "        'umbral_minutos_extremos': UMBRAL_MINUTOS_EXTREMOS,\n",
    "        'peso_destinos': PESO_DESTINOS,\n",
    "        'peso_spray_ratio': PESO_SPRAY_RATIO\n",
    "    },\n",
    "    'parametros_umbral': {\n",
    "        'percentil_base': PERCENTIL_BASE,\n",
    "        'ajuste_umbral': AJUSTE_UMBRAL\n",
    "    }\n",
    "}\n",
    "\n",
    "config_path = os.path.join(MODELS_PATH, \"config_modelo_general.pkl\")\n",
    "with open(config_path, 'wb') as f:\n",
    "    pickle.dump(config_general, f)\n",
    "\n",
    "print(\"‚úÖ Modelo mejorado guardado exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fc5397",
   "metadata": {},
   "source": [
    "# 10. FUNCI√ìN DE PREDICCI√ìN GENERAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9859273b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÆ Funci√≥n de predicci√≥n mejorada definida\n"
     ]
    }
   ],
   "source": [
    "def predecir_anomalia_mejorada(pais, linea, llamadas, minutos, destinos, modelo, scaler, umbral, stats_dict):\n",
    "    \"\"\"\n",
    "    Predicci√≥n con detecci√≥n inteligente de minutos extremos y spray calling\n",
    "    \"\"\"\n",
    "    # Crear row simulado\n",
    "    row_data = {\n",
    "        'CODIGODEPAIS': pais,\n",
    "        'N_LLAMADAS': llamadas,\n",
    "        'N_MINUTOS': minutos,\n",
    "        'N_DESTINOS': destinos\n",
    "    }\n",
    "    \n",
    "    # Crear features mejoradas\n",
    "    features = crear_features_contextualizadas_mejorada(row_data, stats_dict)\n",
    "    \n",
    "    # Normalizar\n",
    "    features_scaled = scaler.transform_one(features)\n",
    "    \n",
    "    # Obtener score\n",
    "    score = modelo.score_one(features_scaled)\n",
    "    \n",
    "    # L√ìGICA MEJORADA PARA CONFIRMACI√ìN DE ANOMAL√çAS\n",
    "    es_anomalia_base = score > umbral\n",
    "    \n",
    "    if es_anomalia_base:\n",
    "        # Confirmar diferentes tipos de anomal√≠as\n",
    "        \n",
    "        # Tipo 1: Minutos extremos (NUEVA DETECCI√ìN)\n",
    "        if minutos >= UMBRAL_MINUTOS_EXTREMOS:\n",
    "            es_anomalia_final = True\n",
    "            razon = f\"Minutos extremos ({minutos:.1f} min)\"\n",
    "        \n",
    "        # Tipo 2: Spray calling confirmado\n",
    "        elif destinos >= 6 and llamadas >= 12:\n",
    "            es_anomalia_final = True\n",
    "            razon = \"Patr√≥n de spray calling confirmado\"\n",
    "        \n",
    "        # Tipo 3: Volumen excepcionalmente alto\n",
    "        elif llamadas > 50 or destinos > 15:\n",
    "            es_anomalia_final = True\n",
    "            razon = \"Volumen excepcionalmente alto\"\n",
    "        \n",
    "        # Tipo 4: Pa√≠s de bajo tr√°fico con actividad sospechosa\n",
    "        elif pais not in stats_dict or stats_dict.get(pais, {}).get('CATEGORIA') in ['Muy_Bajo', 'Bajo']:\n",
    "            if destinos >= 4 and llamadas >= 8:\n",
    "                es_anomalia_final = True\n",
    "                razon = \"Actividad sospechosa en pa√≠s de bajo tr√°fico\"\n",
    "            else:\n",
    "                es_anomalia_final = False\n",
    "                razon = \"Actividad baja en pa√≠s de bajo tr√°fico\"\n",
    "        \n",
    "        # Reglas de exclusi√≥n\n",
    "        elif destinos < 3:\n",
    "            es_anomalia_final = False\n",
    "            razon = \"Muy pocos destinos (<3)\"\n",
    "        elif destinos / max(llamadas, 1) < 0.15:\n",
    "            es_anomalia_final = False\n",
    "            razon = \"Ratio destinos/llamadas muy bajo\"\n",
    "        elif llamadas < 5:\n",
    "            es_anomalia_final = False\n",
    "            razon = \"Muy pocas llamadas (<5)\"\n",
    "        else:\n",
    "            es_anomalia_final = False\n",
    "            razon = \"No cumple criterios de confirmaci√≥n\"\n",
    "    else:\n",
    "        es_anomalia_final = False\n",
    "        razon = \"Score bajo umbral\"\n",
    "    \n",
    "    # Determinar contexto\n",
    "    if pais in stats_dict:\n",
    "        categoria = stats_dict[pais]['CATEGORIA']\n",
    "        tipo_contexto = categoria\n",
    "    else:\n",
    "        tipo_contexto = \"Muy_Bajo\"  # üîß Pa√≠ses nuevos siempre como Muy_Bajo\n",
    "    \n",
    "    return {\n",
    "        'score': score,\n",
    "        'umbral': umbral,\n",
    "        'es_anomalia': es_anomalia_final,\n",
    "        'tipo_contexto': tipo_contexto,\n",
    "        'razon_decision': razon,\n",
    "        'features': features\n",
    "    }\n",
    "\n",
    "print(\"üîÆ Funci√≥n de predicci√≥n mejorada definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ed55e1",
   "metadata": {},
   "source": [
    "# 11. SCORING EN PER√çODO DE PRUEBA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3107e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ Scoring con modelo mejorado...\n",
      "   Scoring: 0/343910 registros\n",
      "   Scoring: 2000/343910 registros\n",
      "   Scoring: 4000/343910 registros\n",
      "   Scoring: 6000/343910 registros\n",
      "   Scoring: 8000/343910 registros\n",
      "   Scoring: 10000/343910 registros\n",
      "   Scoring: 12000/343910 registros\n",
      "   Scoring: 14000/343910 registros\n",
      "   Scoring: 16000/343910 registros\n",
      "   Scoring: 18000/343910 registros\n",
      "   Scoring: 20000/343910 registros\n",
      "   Scoring: 22000/343910 registros\n",
      "   Scoring: 24000/343910 registros\n",
      "   Scoring: 26000/343910 registros\n",
      "   Scoring: 28000/343910 registros\n",
      "   Scoring: 30000/343910 registros\n",
      "   Scoring: 32000/343910 registros\n",
      "   Scoring: 34000/343910 registros\n",
      "   Scoring: 36000/343910 registros\n",
      "   Scoring: 38000/343910 registros\n",
      "   Scoring: 40000/343910 registros\n",
      "   Scoring: 42000/343910 registros\n",
      "   Scoring: 44000/343910 registros\n",
      "   Scoring: 46000/343910 registros\n",
      "   Scoring: 48000/343910 registros\n",
      "   Scoring: 50000/343910 registros\n",
      "   Scoring: 52000/343910 registros\n",
      "   Scoring: 54000/343910 registros\n",
      "   Scoring: 56000/343910 registros\n",
      "   Scoring: 58000/343910 registros\n",
      "   Scoring: 60000/343910 registros\n",
      "   Scoring: 62000/343910 registros\n",
      "   Scoring: 64000/343910 registros\n",
      "   Scoring: 66000/343910 registros\n",
      "   Scoring: 68000/343910 registros\n",
      "   Scoring: 70000/343910 registros\n",
      "   Scoring: 72000/343910 registros\n",
      "   Scoring: 74000/343910 registros\n",
      "   Scoring: 76000/343910 registros\n",
      "   Scoring: 78000/343910 registros\n",
      "   Scoring: 80000/343910 registros\n",
      "   Scoring: 82000/343910 registros\n",
      "   Scoring: 84000/343910 registros\n",
      "   Scoring: 86000/343910 registros\n",
      "   Scoring: 88000/343910 registros\n",
      "   Scoring: 90000/343910 registros\n",
      "   Scoring: 92000/343910 registros\n",
      "   Scoring: 94000/343910 registros\n",
      "   Scoring: 96000/343910 registros\n",
      "   Scoring: 98000/343910 registros\n",
      "   Scoring: 100000/343910 registros\n",
      "   Scoring: 102000/343910 registros\n",
      "   Scoring: 104000/343910 registros\n",
      "   Scoring: 106000/343910 registros\n",
      "   Scoring: 108000/343910 registros\n",
      "   Scoring: 110000/343910 registros\n",
      "   Scoring: 112000/343910 registros\n",
      "   Scoring: 114000/343910 registros\n",
      "   Scoring: 116000/343910 registros\n",
      "   Scoring: 118000/343910 registros\n",
      "   Scoring: 120000/343910 registros\n",
      "   Scoring: 122000/343910 registros\n",
      "   Scoring: 124000/343910 registros\n",
      "   Scoring: 126000/343910 registros\n",
      "   Scoring: 128000/343910 registros\n",
      "   Scoring: 130000/343910 registros\n",
      "   Scoring: 132000/343910 registros\n",
      "   Scoring: 134000/343910 registros\n",
      "   Scoring: 136000/343910 registros\n",
      "   Scoring: 138000/343910 registros\n",
      "   Scoring: 140000/343910 registros\n",
      "   Scoring: 142000/343910 registros\n",
      "   Scoring: 144000/343910 registros\n",
      "   Scoring: 146000/343910 registros\n",
      "   Scoring: 148000/343910 registros\n",
      "   Scoring: 150000/343910 registros\n",
      "   Scoring: 152000/343910 registros\n",
      "   Scoring: 154000/343910 registros\n",
      "   Scoring: 156000/343910 registros\n",
      "   Scoring: 158000/343910 registros\n",
      "   Scoring: 160000/343910 registros\n",
      "   Scoring: 162000/343910 registros\n",
      "   Scoring: 164000/343910 registros\n",
      "   Scoring: 166000/343910 registros\n",
      "   Scoring: 168000/343910 registros\n",
      "   Scoring: 170000/343910 registros\n",
      "   Scoring: 172000/343910 registros\n",
      "   Scoring: 174000/343910 registros\n",
      "   Scoring: 176000/343910 registros\n",
      "   Scoring: 178000/343910 registros\n",
      "   Scoring: 180000/343910 registros\n",
      "   Scoring: 182000/343910 registros\n",
      "   Scoring: 184000/343910 registros\n",
      "   Scoring: 186000/343910 registros\n",
      "   Scoring: 188000/343910 registros\n",
      "   Scoring: 190000/343910 registros\n",
      "   Scoring: 192000/343910 registros\n",
      "   Scoring: 194000/343910 registros\n",
      "   Scoring: 196000/343910 registros\n",
      "   Scoring: 198000/343910 registros\n",
      "   Scoring: 200000/343910 registros\n",
      "   Scoring: 202000/343910 registros\n",
      "   Scoring: 204000/343910 registros\n",
      "   Scoring: 206000/343910 registros\n",
      "   Scoring: 208000/343910 registros\n",
      "   Scoring: 210000/343910 registros\n",
      "   Scoring: 212000/343910 registros\n",
      "   Scoring: 214000/343910 registros\n",
      "   Scoring: 216000/343910 registros\n",
      "   Scoring: 218000/343910 registros\n",
      "   Scoring: 220000/343910 registros\n",
      "   Scoring: 222000/343910 registros\n",
      "   Scoring: 224000/343910 registros\n",
      "   Scoring: 226000/343910 registros\n",
      "   Scoring: 228000/343910 registros\n",
      "   Scoring: 230000/343910 registros\n",
      "   Scoring: 232000/343910 registros\n",
      "   Scoring: 234000/343910 registros\n",
      "   Scoring: 236000/343910 registros\n",
      "   Scoring: 238000/343910 registros\n",
      "   Scoring: 240000/343910 registros\n",
      "   Scoring: 242000/343910 registros\n",
      "   Scoring: 244000/343910 registros\n",
      "   Scoring: 246000/343910 registros\n",
      "   Scoring: 248000/343910 registros\n",
      "   Scoring: 250000/343910 registros\n",
      "   Scoring: 252000/343910 registros\n",
      "   Scoring: 254000/343910 registros\n",
      "   Scoring: 256000/343910 registros\n",
      "   Scoring: 258000/343910 registros\n",
      "   Scoring: 260000/343910 registros\n",
      "   Scoring: 262000/343910 registros\n",
      "   Scoring: 264000/343910 registros\n",
      "   Scoring: 266000/343910 registros\n",
      "   Scoring: 268000/343910 registros\n",
      "   Scoring: 270000/343910 registros\n",
      "   Scoring: 272000/343910 registros\n",
      "   Scoring: 274000/343910 registros\n",
      "   Scoring: 276000/343910 registros\n",
      "   Scoring: 278000/343910 registros\n",
      "   Scoring: 280000/343910 registros\n",
      "   Scoring: 282000/343910 registros\n",
      "   Scoring: 284000/343910 registros\n",
      "   Scoring: 286000/343910 registros\n",
      "   Scoring: 288000/343910 registros\n",
      "   Scoring: 290000/343910 registros\n",
      "   Scoring: 292000/343910 registros\n",
      "   Scoring: 294000/343910 registros\n",
      "   Scoring: 296000/343910 registros\n",
      "   Scoring: 298000/343910 registros\n",
      "   Scoring: 300000/343910 registros\n",
      "   Scoring: 302000/343910 registros\n",
      "   Scoring: 304000/343910 registros\n",
      "   Scoring: 306000/343910 registros\n",
      "   Scoring: 308000/343910 registros\n",
      "   Scoring: 310000/343910 registros\n",
      "   Scoring: 312000/343910 registros\n",
      "   Scoring: 314000/343910 registros\n",
      "   Scoring: 316000/343910 registros\n",
      "   Scoring: 318000/343910 registros\n",
      "   Scoring: 320000/343910 registros\n",
      "   Scoring: 322000/343910 registros\n",
      "   Scoring: 324000/343910 registros\n",
      "   Scoring: 326000/343910 registros\n",
      "   Scoring: 328000/343910 registros\n",
      "   Scoring: 330000/343910 registros\n",
      "   Scoring: 332000/343910 registros\n",
      "   Scoring: 334000/343910 registros\n",
      "   Scoring: 336000/343910 registros\n",
      "   Scoring: 338000/343910 registros\n",
      "   Scoring: 340000/343910 registros\n",
      "   Scoring: 342000/343910 registros\n",
      "‚úÖ Scoring mejorado completado\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüéØ Scoring con modelo mejorado...\")\n",
    "\n",
    "resultados_mejorados = []\n",
    "\n",
    "for contador, (idx, row) in enumerate(df_scoring.iterrows()):\n",
    "    if contador % 2000 == 0:\n",
    "        print(f\"   Scoring: {contador}/{len(df_scoring)} registros\")\n",
    "    \n",
    "    resultado = predecir_anomalia_mejorada(\n",
    "        pais=row['CODIGODEPAIS'],\n",
    "        linea=row['LINEA'],\n",
    "        llamadas=row['N_LLAMADAS'],\n",
    "        minutos=row['N_MINUTOS'],\n",
    "        destinos=row['N_DESTINOS'],\n",
    "        modelo=modelo_mejorado,\n",
    "        scaler=scaler_mejorado,\n",
    "        umbral=umbral_objetivo,\n",
    "        stats_dict=stats_dict\n",
    "    )\n",
    "    \n",
    "    resultado_completo = {\n",
    "        'FECHA': row['FECHA'],\n",
    "        'CODIGODEPAIS': row['CODIGODEPAIS'],\n",
    "        'LINEA': row['LINEA'],\n",
    "        'N_LLAMADAS': row['N_LLAMADAS'],\n",
    "        'N_MINUTOS': row['N_MINUTOS'],\n",
    "        'N_DESTINOS': row['N_DESTINOS'],\n",
    "        'score_anomalia': resultado['score'],\n",
    "        'umbral': resultado['umbral'],\n",
    "        'es_anomalia': resultado['es_anomalia'],\n",
    "        'tipo_contexto': resultado['tipo_contexto'],\n",
    "        'razon_decision': resultado['razon_decision']\n",
    "    }\n",
    "    \n",
    "    resultados_mejorados.append(resultado_completo)\n",
    "\n",
    "df_resultados_mejorados = pd.DataFrame(resultados_mejorados)\n",
    "\n",
    "print(\"‚úÖ Scoring mejorado completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc821f58",
   "metadata": {},
   "source": [
    "# 12. AN√ÅLISIS DETALLADO DE RESULTADOS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffc8011e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä RESULTADOS CON MODELO MEJORADO:\n",
      "üìû Total de l√≠neas evaluadas: 343910\n",
      "üö® Anomal√≠as detectadas: 2507\n",
      "üìà Tasa de anomal√≠as: 0.729%\n",
      "\n",
      "üîç RAZONES DE DECISIONES:\n",
      "razon_decision\n",
      "Score bajo umbral                         341175\n",
      "Patr√≥n de spray calling confirmado          2378\n",
      "No cumple criterios de confirmaci√≥n          127\n",
      "Actividad baja en pa√≠s de bajo tr√°fico        98\n",
      "Ratio destinos/llamadas muy bajo               3\n",
      "                                           ...  \n",
      "Minutos extremos (597.6 min)                   1\n",
      "Minutos extremos (558.3 min)                   1\n",
      "Minutos extremos (518.3 min)                   1\n",
      "Minutos extremos (419.6 min)                   1\n",
      "Minutos extremos (350.1 min)                   1\n",
      "Name: count, Length: 129, dtype: int64\n",
      "\n",
      "üéØ ANOMAL√çAS CONFIRMADAS (Top 10):\n",
      "        CODIGODEPAIS        LINEA  N_LLAMADAS  N_MINUTOS  N_DESTINOS  \\\n",
      "70256            593  51880609481         327     726.00         308   \n",
      "76478            593  51880609481         283     829.47         272   \n",
      "241913           593  51880609481         253     305.33         245   \n",
      "234282           593  51864259326         153     334.87         150   \n",
      "103488           593  51856106975         227     344.20         222   \n",
      "259450           593  51880609481         277     423.20         271   \n",
      "103362           593  51880609481         275     579.30         271   \n",
      "102180           593  51880609481         257     495.98         252   \n",
      "221213           593  51854856835         371     571.94         360   \n",
      "226937           593  51801304879         396     548.95         377   \n",
      "\n",
      "        score_anomalia                razon_decision  \n",
      "70256          0.99843  Minutos extremos (726.0 min)  \n",
      "76478          0.99843  Minutos extremos (829.5 min)  \n",
      "241913         0.99843  Minutos extremos (305.3 min)  \n",
      "234282         0.99843  Minutos extremos (334.9 min)  \n",
      "103488         0.99843  Minutos extremos (344.2 min)  \n",
      "259450         0.99843  Minutos extremos (423.2 min)  \n",
      "103362         0.99843  Minutos extremos (579.3 min)  \n",
      "102180         0.99843  Minutos extremos (496.0 min)  \n",
      "221213         0.99843  Minutos extremos (571.9 min)  \n",
      "226937         0.99843  Minutos extremos (549.0 min)  \n",
      "\n",
      "üìä ESTAD√çSTICAS DE ANOMAL√çAS CONFIRMADAS:\n",
      "üìû Llamadas - Min: 2, Max: 462, Media: 45.2\n",
      "üéØ Destinos - Min: 1, Max: 438, Media: 42.7\n",
      "‚è±Ô∏è Minutos - Min: 0.71, Max: 829.47, Media: 88.1\n",
      "üìä Ratio Destinos/Llamadas promedio: 0.917\n",
      "\n",
      "‚ö° DETECCIONES POR MINUTOS EXTREMOS: 124\n",
      "‚è±Ô∏è Minutos promedio en extremos: 466.0\n",
      "\n",
      "‚úÖ MEJORAS IMPLEMENTADAS:\n",
      "üîß Detecci√≥n inteligente de minutos extremos (‚â•300 min)\n",
      "üåç Pa√≠ses nuevos clasificados como 'Muy_Bajo' autom√°ticamente\n",
      "üìä Umbral configurable (P99 √ó 1.0)\n",
      "üõ°Ô∏è Reglas mejoradas anti-falsos positivos\n",
      "üéØ Mayor sensibilidad para pa√≠ses de bajo tr√°fico\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüìä RESULTADOS CON MODELO MEJORADO:\")\n",
    "print(f\"üìû Total de l√≠neas evaluadas: {len(df_resultados_mejorados)}\")\n",
    "print(f\"üö® Anomal√≠as detectadas: {df_resultados_mejorados['es_anomalia'].sum()}\")\n",
    "print(f\"üìà Tasa de anomal√≠as: {df_resultados_mejorados['es_anomalia'].mean()*100:.3f}%\")\n",
    "\n",
    "# An√°lisis de razones de decisi√≥n\n",
    "print(f\"\\nüîç RAZONES DE DECISIONES:\")\n",
    "razones = df_resultados_mejorados['razon_decision'].value_counts()\n",
    "print(razones)\n",
    "\n",
    "# Anomal√≠as confirmadas\n",
    "anomalias_confirmadas = df_resultados_mejorados[df_resultados_mejorados['es_anomalia'] == True]\n",
    "if len(anomalias_confirmadas) > 0:\n",
    "    print(f\"\\nüéØ ANOMAL√çAS CONFIRMADAS (Top 10):\")\n",
    "    print(anomalias_confirmadas.sort_values('score_anomalia', ascending=False)[\n",
    "        ['CODIGODEPAIS', 'LINEA', 'N_LLAMADAS', 'N_MINUTOS', 'N_DESTINOS', \n",
    "         'score_anomalia', 'razon_decision']\n",
    "    ].head(10))\n",
    "    \n",
    "    # Estad√≠sticas de anomal√≠as confirmadas\n",
    "    print(f\"\\nüìä ESTAD√çSTICAS DE ANOMAL√çAS CONFIRMADAS:\")\n",
    "    print(f\"üìû Llamadas - Min: {anomalias_confirmadas['N_LLAMADAS'].min()}, Max: {anomalias_confirmadas['N_LLAMADAS'].max()}, Media: {anomalias_confirmadas['N_LLAMADAS'].mean():.1f}\")\n",
    "    print(f\"üéØ Destinos - Min: {anomalias_confirmadas['N_DESTINOS'].min()}, Max: {anomalias_confirmadas['N_DESTINOS'].max()}, Media: {anomalias_confirmadas['N_DESTINOS'].mean():.1f}\")\n",
    "    print(f\"‚è±Ô∏è Minutos - Min: {anomalias_confirmadas['N_MINUTOS'].min()}, Max: {anomalias_confirmadas['N_MINUTOS'].max()}, Media: {anomalias_confirmadas['N_MINUTOS'].mean():.1f}\")\n",
    "    print(f\"üìä Ratio Destinos/Llamadas promedio: {(anomalias_confirmadas['N_DESTINOS']/anomalias_confirmadas['N_LLAMADAS']).mean():.3f}\")\n",
    "    \n",
    "    # An√°lisis de minutos extremos\n",
    "    minutos_extremos = anomalias_confirmadas[anomalias_confirmadas['razon_decision'].str.contains('Minutos extremos')]\n",
    "    if len(minutos_extremos) > 0:\n",
    "        print(f\"\\n‚ö° DETECCIONES POR MINUTOS EXTREMOS: {len(minutos_extremos)}\")\n",
    "        print(f\"‚è±Ô∏è Minutos promedio en extremos: {minutos_extremos['N_MINUTOS'].mean():.1f}\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No se detectaron anomal√≠as\")\n",
    "\n",
    "print(f\"\\n‚úÖ MEJORAS IMPLEMENTADAS:\")\n",
    "print(f\"üîß Detecci√≥n inteligente de minutos extremos (‚â•{UMBRAL_MINUTOS_EXTREMOS} min)\")\n",
    "print(f\"üåç Pa√≠ses nuevos clasificados como 'Muy_Bajo' autom√°ticamente\")\n",
    "print(f\"üìä Umbral configurable (P{PERCENTIL_BASE} √ó {AJUSTE_UMBRAL})\")\n",
    "print(f\"üõ°Ô∏è Reglas mejoradas anti-falsos positivos\")\n",
    "print(f\"üéØ Mayor sensibilidad para pa√≠ses de bajo tr√°fico\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a672f75b",
   "metadata": {},
   "source": [
    "# 13. GUARDAR RESULTADOS FINALES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b8c7f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üö® Solo anomal√≠as: C:\\Users\\User\\Desktop\\TESIS\\Modelos\\anomalias_modelo_general.csv\n",
      "\n",
      "üíæ RESULTADOS GUARDADOS:\n",
      "üìÑ Todos los resultados: C:\\Users\\User\\Desktop\\TESIS\\Modelos\\resultados_modelo_general.csv\n"
     ]
    }
   ],
   "source": [
    "# Guardar todos los resultados\n",
    "resultados_path = os.path.join(MODELS_PATH, \"resultados_modelo_general.csv\")\n",
    "df_resultados_mejorados.to_csv(resultados_path, index=False)\n",
    "\n",
    "# Guardar solo anomal√≠as si existen\n",
    "if len(anomalias_confirmadas) > 0:\n",
    "    anomalias_path = os.path.join(MODELS_PATH, \"anomalias_modelo_general.csv\")\n",
    "    anomalias_confirmadas.to_csv(anomalias_path, index=False)\n",
    "    print(f\"üö® Solo anomal√≠as: {anomalias_path}\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No hay anomal√≠as para guardar por separado\")\n",
    "\n",
    "print(f\"\\nüíæ RESULTADOS GUARDADOS:\")\n",
    "print(f\"üìÑ Todos los resultados: {resultados_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6406db85",
   "metadata": {},
   "source": [
    "# # 14. FUNCI√ìN PARA PROBAR REGISTROS INDIVIDUALES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3206e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probar_registro_individual(pais, linea, llamadas, minutos, destinos, mostrar_detalles=True):\n",
    "    \"\"\"\n",
    "    Funci√≥n para probar un registro individual y ver el an√°lisis completo\n",
    "    \n",
    "    Par√°metros:\n",
    "    - pais: C√≥digo del pa√≠s (ej: \"1\", \"34\", \"591\")\n",
    "    - linea: N√∫mero de l√≠nea telef√≥nica (ej: \"70123456\")\n",
    "    - llamadas: N√∫mero de llamadas realizadas\n",
    "    - minutos: Minutos totales de las llamadas\n",
    "    - destinos: N√∫mero de destinos √∫nicos\n",
    "    - mostrar_detalles: Si mostrar an√°lisis detallado (True/False)\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîç AN√ÅLISIS DE REGISTRO INDIVIDUAL\")\n",
    "    print(f\"=\" * 50)\n",
    "    print(f\"üåç Pa√≠s: {pais}\")\n",
    "    print(f\"üìû L√≠nea: {linea}\")\n",
    "    print(f\"üìä Llamadas: {llamadas}\")\n",
    "    print(f\"‚è±Ô∏è Minutos: {minutos}\")\n",
    "    print(f\"üéØ Destinos: {destinos}\")\n",
    "    print(f\"-\" * 50)\n",
    "    \n",
    "    # Realizar predicci√≥n\n",
    "    resultado = predecir_anomalia_mejorada(\n",
    "        pais=pais,\n",
    "        linea=linea,\n",
    "        llamadas=llamadas,\n",
    "        minutos=minutos,\n",
    "        destinos=destinos,\n",
    "        modelo=modelo_mejorado,\n",
    "        scaler=scaler_mejorado,\n",
    "        umbral=umbral_objetivo,\n",
    "        stats_dict=stats_dict\n",
    "    )\n",
    "    \n",
    "    # Mostrar resultado principal\n",
    "    if resultado['es_anomalia']:\n",
    "        print(f\"üö® RESULTADO: ANOMAL√çA DETECTADA\")\n",
    "        print(f\"üî¥ Score: {resultado['score']:.4f} (Umbral: {resultado['umbral']:.4f})\")\n",
    "    else:\n",
    "        print(f\"‚úÖ RESULTADO: REGISTRO NORMAL\")\n",
    "        print(f\"üü¢ Score: {resultado['score']:.4f} (Umbral: {resultado['umbral']:.4f})\")\n",
    "    \n",
    "    print(f\"üè∑Ô∏è Contexto del pa√≠s: {resultado['tipo_contexto']}\")\n",
    "    print(f\"üí≠ Raz√≥n: {resultado['razon_decision']}\")\n",
    "    \n",
    "    if mostrar_detalles:\n",
    "        print(f\"\\nüìã AN√ÅLISIS DETALLADO:\")\n",
    "        print(f\"-\" * 30)\n",
    "        \n",
    "        # Mostrar contexto del pa√≠s\n",
    "        if pais in stats_dict:\n",
    "            pais_stats = stats_dict[pais]\n",
    "            print(f\"üìä Estad√≠sticas del pa√≠s {pais}:\")\n",
    "            print(f\"   üìû Llamadas P95: {pais_stats['LLAMADAS_P95']:.1f}\")\n",
    "            print(f\"   ‚è±Ô∏è Minutos P95: {pais_stats['MINUTOS_P95']:.1f}\")\n",
    "            print(f\"   üéØ Destinos P95: {pais_stats['DESTINOS_P95']:.1f}\")\n",
    "            print(f\"   üìà Categor√≠a: {pais_stats['CATEGORIA']}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Pa√≠s {pais} no encontrado en estad√≠sticas (pa√≠s nuevo)\")\n",
    "        \n",
    "        # Mostrar features calculadas\n",
    "        print(f\"\\nüîß CARACTER√çSTICAS CALCULADAS:\")\n",
    "        features = resultado['features']\n",
    "        for key, value in features.items():\n",
    "            if value > 0:  # Solo mostrar features activas\n",
    "                print(f\"   {key}: {value:.3f}\")\n",
    "        \n",
    "        # An√°lisis de patrones\n",
    "        print(f\"\\nüéØ AN√ÅLISIS DE PATRONES:\")\n",
    "        ratio_destinos = destinos / max(llamadas, 1)\n",
    "        minutos_por_llamada = minutos / max(llamadas, 1)\n",
    "        \n",
    "        print(f\"   üìä Ratio destinos/llamadas: {ratio_destinos:.3f}\")\n",
    "        print(f\"   ‚è±Ô∏è Minutos por llamada: {minutos_por_llamada:.2f}\")\n",
    "        \n",
    "        # Indicadores de riesgo\n",
    "        print(f\"\\n‚ö†Ô∏è INDICADORES DE RIESGO:\")\n",
    "        \n",
    "        if destinos >= 10 and llamadas >= 20:\n",
    "            print(f\"   üî¥ Patr√≥n de spray calling fuerte detectado\")\n",
    "        elif destinos >= 6 and llamadas >= 12:\n",
    "            print(f\"   üü° Patr√≥n de spray calling medio detectado\")\n",
    "        \n",
    "        if minutos >= UMBRAL_MINUTOS_EXTREMOS:\n",
    "            print(f\"   üî¥ Minutos extremos detectados (‚â•{UMBRAL_MINUTOS_EXTREMOS})\")\n",
    "        \n",
    "        if ratio_destinos >= 0.5:\n",
    "            print(f\"   üü° Alta diversidad de destinos (‚â•50%)\")\n",
    "        \n",
    "        if minutos_por_llamada < 2:\n",
    "            print(f\"   üü° Llamadas muy cortas (posible exploraci√≥n)\")\n",
    "        \n",
    "        if llamadas > 50 or destinos > 15:\n",
    "            print(f\"   üî¥ Volumen excepcionalmente alto\")\n",
    "    \n",
    "    print(f\"=\" * 50)\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "480689af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç AN√ÅLISIS DE REGISTRO INDIVIDUAL\n",
      "==================================================\n",
      "üåç Pa√≠s: 1\n",
      "üìû L√≠nea: 70123456\n",
      "üìä Llamadas: 12\n",
      "‚è±Ô∏è Minutos: 20\n",
      "üéØ Destinos: 1\n",
      "--------------------------------------------------\n",
      "‚úÖ RESULTADO: REGISTRO NORMAL\n",
      "üü¢ Score: 0.9002 (Umbral: 0.9724)\n",
      "üè∑Ô∏è Contexto del pa√≠s: Alto\n",
      "üí≠ Raz√≥n: Score bajo umbral\n",
      "\n",
      "üìã AN√ÅLISIS DETALLADO:\n",
      "------------------------------\n",
      "üìä Estad√≠sticas del pa√≠s 1:\n",
      "   üìû Llamadas P95: 5.0\n",
      "   ‚è±Ô∏è Minutos P95: 49.4\n",
      "   üéØ Destinos P95: 2.0\n",
      "   üìà Categor√≠a: Alto\n",
      "\n",
      "üîß CARACTER√çSTICAS CALCULADAS:\n",
      "   llamadas_norm: 1.200\n",
      "   destinos_norm: 0.600\n",
      "   minutos_norm: 0.349\n",
      "   diversidad_destinos: 0.083\n",
      "   llamadas_por_destino: 1.000\n",
      "   eficiencia_destinos: 0.167\n",
      "   factor_pais_bajo: 1.000\n",
      "   factor_pais_alto: 0.900\n",
      "\n",
      "üéØ AN√ÅLISIS DE PATRONES:\n",
      "   üìä Ratio destinos/llamadas: 0.083\n",
      "   ‚è±Ô∏è Minutos por llamada: 1.67\n",
      "\n",
      "‚ö†Ô∏è INDICADORES DE RIESGO:\n",
      "   üü° Llamadas muy cortas (posible exploraci√≥n)\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.9002249633610161,\n",
       " 'umbral': np.float64(0.9724393551538845),\n",
       " 'es_anomalia': False,\n",
       " 'tipo_contexto': 'Alto',\n",
       " 'razon_decision': 'Score bajo umbral',\n",
       " 'features': {'llamadas_norm': 1.2000000000000002,\n",
       "  'destinos_norm': 0.6,\n",
       "  'minutos_norm': np.float64(0.3488690925491036),\n",
       "  'diversidad_destinos': 0.08333333333333333,\n",
       "  'spray_ratio': 0,\n",
       "  'minutos_extremos': 0.0,\n",
       "  'minutos_sospechosos': 0.0,\n",
       "  'patron_spray_fuerte': 0.0,\n",
       "  'patron_spray_medio': 0.0,\n",
       "  'alta_diversidad': 0,\n",
       "  'volumen_llamadas_alto': 0,\n",
       "  'volumen_destinos_alto': 0,\n",
       "  'llamadas_por_destino': 1,\n",
       "  'eficiencia_destinos': 0.16666666666666666,\n",
       "  'factor_pais_bajo': 1.0,\n",
       "  'factor_pais_alto': 0.9}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probar_registro_individual(pais=1, linea='70123456', llamadas=12, minutos=20, destinos=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf4b40d",
   "metadata": {},
   "source": [
    "# # 15. REINICIALIZACI√ìN Y CARGA DEL MODELO ENTRENADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c29c093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Librer√≠as importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from river import anomaly\n",
    "from river import preprocessing\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991a83f9",
   "metadata": {},
   "source": [
    "# # 16. CONFIGURACI√ìN DE RUTAS Y CARGA DE MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73348a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Directorio de modelos: C:\\Users\\User\\Desktop\\TESIS\\Modelos\n"
     ]
    }
   ],
   "source": [
    "# Rutas de archivos\n",
    "MODELS_PATH = r\"C:\\Users\\User\\Desktop\\TESIS\\Modelos\"\n",
    "EVALUATION_CSV_PATH = r\"C:\\Users\\User\\Desktop\\TESIS\\NuevoDataSet\\DataSetFinalProbarMatriz.csv\"  # üîß CAMBIAR ESTA RUTA\n",
    "\n",
    "# Verificar que el directorio de modelos existe\n",
    "if not os.path.exists(MODELS_PATH):\n",
    "    print(f\"‚ùå Error: Directorio de modelos no encontrado: {MODELS_PATH}\")\n",
    "    exit()\n",
    "\n",
    "print(f\"üìÅ Directorio de modelos: {MODELS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aa3593",
   "metadata": {},
   "source": [
    "# # 17. CARGAR MODELO, SCALER Y CONFIGURACI√ìN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "728092c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Cargando modelo entrenado...\n",
      "‚úÖ Modelo cargado exitosamente\n",
      "\n",
      "üìä INFORMACI√ìN DEL MODELO CARGADO:\n",
      "üéØ Umbral global: 0.9724\n",
      "üåç Pa√≠ses en entrenamiento: 188\n",
      "üìà Registros de entrenamiento: 450900\n",
      "üìÖ Fecha de entrenamiento: 2025-06-09T18:10:07.358019\n",
      "üå≥ N√∫mero de √°rboles: 80\n",
      "üìè Altura de √°rboles: 10\n",
      "\n",
      "‚öôÔ∏è PAR√ÅMETROS DE FEATURES CARGADOS:\n",
      "üîß Peso minutos normal: 0.4\n",
      "üîß Peso minutos extremos: 1.5\n",
      "üîß Umbral minutos extremos: 300\n",
      "üîß Peso destinos: 1.2\n",
      "üîß Peso spray ratio: 1.5\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîÑ Cargando modelo entrenado...\")\n",
    "\n",
    "# Cargar modelo\n",
    "modelo_path = os.path.join(MODELS_PATH, \"modelo_general.pkl\")\n",
    "with open(modelo_path, 'rb') as f:\n",
    "    modelo_cargado = pickle.load(f)\n",
    "\n",
    "# Cargar scaler\n",
    "scaler_path = os.path.join(MODELS_PATH, \"scaler_general.pkl\")\n",
    "with open(scaler_path, 'rb') as f:\n",
    "    scaler_cargado = pickle.load(f)\n",
    "\n",
    "# Cargar configuraci√≥n\n",
    "config_path = os.path.join(MODELS_PATH, \"config_modelo_general.pkl\")\n",
    "with open(config_path, 'rb') as f:\n",
    "    config_cargado = pickle.load(f)\n",
    "\n",
    "print(\"‚úÖ Modelo cargado exitosamente\")\n",
    "\n",
    "# Mostrar informaci√≥n del modelo\n",
    "print(f\"\\nüìä INFORMACI√ìN DEL MODELO CARGADO:\")\n",
    "print(f\"üéØ Umbral global: {config_cargado['umbral_global']:.4f}\")\n",
    "print(f\"üåç Pa√≠ses en entrenamiento: {config_cargado['paises_entrenamiento']}\")\n",
    "print(f\"üìà Registros de entrenamiento: {config_cargado['registros_entrenamiento']}\")\n",
    "print(f\"üìÖ Fecha de entrenamiento: {config_cargado['fecha_entrenamiento']}\")\n",
    "print(f\"üå≥ N√∫mero de √°rboles: {config_cargado['n_trees']}\")\n",
    "print(f\"üìè Altura de √°rboles: {config_cargado['tree_height']}\")\n",
    "\n",
    "# Extraer configuraciones\n",
    "umbral_global = config_cargado['umbral_global']\n",
    "stats_por_pais_dict = config_cargado['stats_por_pais']\n",
    "parametros_features = config_cargado['parametros_features']\n",
    "\n",
    "# Configurar par√°metros de features\n",
    "PESO_MINUTOS_NORMAL = parametros_features['peso_minutos_normal']\n",
    "PESO_MINUTOS_EXTREMOS = parametros_features['peso_minutos_extremos']\n",
    "UMBRAL_MINUTOS_EXTREMOS = parametros_features['umbral_minutos_extremos']\n",
    "PESO_DESTINOS = parametros_features['peso_destinos']\n",
    "PESO_SPRAY_RATIO = parametros_features['peso_spray_ratio']\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è PAR√ÅMETROS DE FEATURES CARGADOS:\")\n",
    "print(f\"üîß Peso minutos normal: {PESO_MINUTOS_NORMAL}\")\n",
    "print(f\"üîß Peso minutos extremos: {PESO_MINUTOS_EXTREMOS}\")\n",
    "print(f\"üîß Umbral minutos extremos: {UMBRAL_MINUTOS_EXTREMOS}\")\n",
    "print(f\"üîß Peso destinos: {PESO_DESTINOS}\")\n",
    "print(f\"üîß Peso spray ratio: {PESO_SPRAY_RATIO}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df59e26c",
   "metadata": {},
   "source": [
    "# # 18. REDEFINIR FUNCIONES NECESARIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "575e6aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Funciones redefinidas correctamente\n"
     ]
    }
   ],
   "source": [
    "def crear_features_contextualizadas_mejorada(row, stats_pais_dict):\n",
    "    \"\"\"\n",
    "    Crea caracter√≠sticas balanceadas que detecten minutos extremos y spray calling\n",
    "    \"\"\"\n",
    "    pais = row['CODIGODEPAIS']\n",
    "    llamadas = row['N_LLAMADAS']\n",
    "    minutos = row['N_MINUTOS']\n",
    "    destinos = row['N_DESTINOS']\n",
    "    \n",
    "    # Obtener contexto del pa√≠s (si existe)\n",
    "    if pais in stats_pais_dict:\n",
    "        pais_stats = stats_pais_dict[pais]\n",
    "        categoria = pais_stats['CATEGORIA']\n",
    "        \n",
    "        # Normalizar por el contexto del pa√≠s\n",
    "        llamadas_norm = min(llamadas / max(pais_stats['LLAMADAS_P95'], 1), 1.5)\n",
    "        destinos_norm = min(destinos / max(pais_stats['DESTINOS_P95'], 1), 1.5)\n",
    "        \n",
    "        # MEJORA: Detecci√≥n inteligente de minutos extremos\n",
    "        minutos_p90 = pais_stats.get('MINUTOS_P90', pais_stats['MINUTOS_P95'] * 0.9)\n",
    "        minutos_p95 = pais_stats['MINUTOS_P95']\n",
    "        \n",
    "        # Transformaci√≥n adaptativa de minutos\n",
    "        if minutos >= UMBRAL_MINUTOS_EXTREMOS:  # üîß Minutos extremos\n",
    "            minutos_norm = min(minutos / max(minutos_p90, 1), 3.0)  # Mayor rango para extremos\n",
    "            peso_minutos = PESO_MINUTOS_EXTREMOS  # Peso alto para extremos\n",
    "        else:\n",
    "            minutos_norm = min(np.log1p(minutos) / np.log1p(max(minutos_p90, 1)), 1.2)\n",
    "            peso_minutos = PESO_MINUTOS_NORMAL  # Peso normal\n",
    "            \n",
    "    else:\n",
    "        # Pa√≠s nuevo - SIEMPRE clasificar como 'Muy_Bajo'\n",
    "        categoria = 'Muy_Bajo'\n",
    "        llamadas_norm = min(llamadas / 10, 2.0)  # M√°s sensible para pa√≠ses nuevos\n",
    "        destinos_norm = min(destinos / 5, 2.0)   # M√°s sensible para pa√≠ses nuevos\n",
    "        \n",
    "        # Para pa√≠ses nuevos, ser m√°s sensible a minutos altos\n",
    "        if minutos >= UMBRAL_MINUTOS_EXTREMOS:\n",
    "            minutos_norm = min(minutos / 50, 3.0)  # Muy sensible a minutos extremos\n",
    "            peso_minutos = PESO_MINUTOS_EXTREMOS * 1.2  # Peso extra para pa√≠ses nuevos\n",
    "        else:\n",
    "            minutos_norm = min(np.log1p(minutos) / np.log1p(60), 1.2)\n",
    "            peso_minutos = PESO_MINUTOS_NORMAL\n",
    "    \n",
    "    # Features principales - REBALANCEADAS con detecci√≥n de extremos\n",
    "    features = {\n",
    "        # 1. Valores normalizados con peso adaptativo\n",
    "        'llamadas_norm': llamadas_norm * 0.8,\n",
    "        'destinos_norm': destinos_norm * PESO_DESTINOS,  # üîß Ajustable\n",
    "        'minutos_norm': minutos_norm * peso_minutos,     # üîß Peso adaptativo\n",
    "        \n",
    "        # 2. Ratios cr√≠ticos para fraude\n",
    "        'diversidad_destinos': min(destinos / max(llamadas, 1), 1.0),\n",
    "        'spray_ratio': min(destinos / max(llamadas, 1) * PESO_SPRAY_RATIO, 1.0) if destinos >= 5 else 0,\n",
    "        \n",
    "        # 3. NUEVA: Detecci√≥n espec√≠fica de minutos extremos\n",
    "        'minutos_extremos': 1.0 if minutos >= UMBRAL_MINUTOS_EXTREMOS else 0.0,\n",
    "        'minutos_sospechosos': min((minutos - 200) / 300, 1.0) if minutos > 200 else 0.0,\n",
    "        \n",
    "        # 4. Patrones de fraude\n",
    "        'patron_spray_fuerte': 1.0 if (destinos >= 10 and llamadas >= 20) else 0.0,\n",
    "        'patron_spray_medio': 0.5 if (destinos >= 6 and llamadas >= 12) else 0.0,\n",
    "        'alta_diversidad': min(destinos / 12, 1) if destinos >= 5 else 0,\n",
    "        \n",
    "        # 5. Indicadores de volumen an√≥malo\n",
    "        'volumen_llamadas_alto': min((llamadas - 30) / 50, 1) if llamadas > 30 else 0,\n",
    "        'volumen_destinos_alto': min((destinos - 10) / 20, 1) if destinos > 10 else 0,\n",
    "        \n",
    "        # 6. Caracter√≠sticas de comportamiento\n",
    "        'llamadas_por_destino': min(llamadas / max(destinos, 1) / 5, 1),\n",
    "        'eficiencia_destinos': min(destinos / max(llamadas * 0.5, 1), 1),\n",
    "        \n",
    "        # 7. MEJORA: Ajuste por contexto de pa√≠s\n",
    "        'factor_pais_bajo': 1.5 if categoria in ['Muy_Bajo', 'Bajo'] else 1.0,  # M√°s sensible\n",
    "        'factor_pais_alto': 0.9 if categoria in ['Alto', 'Medio'] else 1.0      # Menos sensible\n",
    "    }\n",
    "    \n",
    "    return features\n",
    "\n",
    "def predecir_anomalia_mejorada(pais, linea, llamadas, minutos, destinos, modelo, scaler, umbral, stats_dict):\n",
    "    \"\"\"\n",
    "    Predicci√≥n con detecci√≥n inteligente de minutos extremos y spray calling\n",
    "    \"\"\"\n",
    "    # Crear row simulado\n",
    "    row_data = {\n",
    "        'CODIGODEPAIS': pais,\n",
    "        'N_LLAMADAS': llamadas,\n",
    "        'N_MINUTOS': minutos,\n",
    "        'N_DESTINOS': destinos\n",
    "    }\n",
    "    \n",
    "    # Crear features mejoradas\n",
    "    features = crear_features_contextualizadas_mejorada(row_data, stats_dict)\n",
    "    \n",
    "    # Normalizar\n",
    "    features_scaled = scaler.transform_one(features)\n",
    "    \n",
    "    # Obtener score\n",
    "    score = modelo.score_one(features_scaled)\n",
    "    \n",
    "    # L√ìGICA MEJORADA PARA CONFIRMACI√ìN DE ANOMAL√çAS\n",
    "    es_anomalia_base = score > umbral\n",
    "    \n",
    "    if es_anomalia_base:\n",
    "        # Confirmar diferentes tipos de anomal√≠as\n",
    "        \n",
    "        # Tipo 1: Minutos extremos (NUEVA DETECCI√ìN)\n",
    "        if minutos >= UMBRAL_MINUTOS_EXTREMOS:\n",
    "            es_anomalia_final = True\n",
    "            razon = f\"Minutos extremos ({minutos:.1f} min)\"\n",
    "        \n",
    "        # Tipo 2: Spray calling confirmado\n",
    "        elif destinos >= 6 and llamadas >= 12:\n",
    "            es_anomalia_final = True\n",
    "            razon = \"Patr√≥n de spray calling confirmado\"\n",
    "        \n",
    "        # Tipo 3: Volumen excepcionalmente alto\n",
    "        elif llamadas > 50 or destinos > 15:\n",
    "            es_anomalia_final = True\n",
    "            razon = \"Volumen excepcionalmente alto\"\n",
    "        \n",
    "        # Tipo 4: Pa√≠s de bajo tr√°fico con actividad sospechosa\n",
    "        elif pais not in stats_dict or stats_dict.get(pais, {}).get('CATEGORIA') in ['Muy_Bajo', 'Bajo']:\n",
    "            if destinos >= 4 and llamadas >= 8:\n",
    "                es_anomalia_final = True\n",
    "                razon = \"Actividad sospechosa en pa√≠s de bajo tr√°fico\"\n",
    "            else:\n",
    "                es_anomalia_final = False\n",
    "                razon = \"Actividad baja en pa√≠s de bajo tr√°fico\"\n",
    "        \n",
    "        # Reglas de exclusi√≥n\n",
    "        elif destinos < 3:\n",
    "            es_anomalia_final = False\n",
    "            razon = \"Muy pocos destinos (<3)\"\n",
    "        elif destinos / max(llamadas, 1) < 0.15:\n",
    "            es_anomalia_final = False\n",
    "            razon = \"Ratio destinos/llamadas muy bajo\"\n",
    "        elif llamadas < 5:\n",
    "            es_anomalia_final = False\n",
    "            razon = \"Muy pocas llamadas (<5)\"\n",
    "        else:\n",
    "            es_anomalia_final = False\n",
    "            razon = \"No cumple criterios de confirmaci√≥n\"\n",
    "    else:\n",
    "        es_anomalia_final = False\n",
    "        razon = \"Score bajo umbral\"\n",
    "    \n",
    "    # Determinar contexto\n",
    "    if pais in stats_dict:\n",
    "        categoria = stats_dict[pais]['CATEGORIA']\n",
    "        tipo_contexto = categoria\n",
    "    else:\n",
    "        tipo_contexto = \"Muy_Bajo\"  # üîß Pa√≠ses nuevos siempre como Muy_Bajo\n",
    "    \n",
    "    return {\n",
    "        'score': score,\n",
    "        'umbral': umbral,\n",
    "        'es_anomalia': es_anomalia_final,\n",
    "        'tipo_contexto': tipo_contexto,\n",
    "        'razon_decision': razon,\n",
    "        'features': features\n",
    "    }\n",
    "\n",
    "print(\"üîß Funciones redefinidas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205bfbd8",
   "metadata": {},
   "source": [
    "# # 19. CARGAR DATASET DE EVALUACI√ìN CON ETIQUETAS DE FRAUDE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e606247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Cargando dataset de evaluaci√≥n...\n",
      "‚úÖ Dataset cargado - Shape: (102684, 7)\n",
      "üîç AN√ÅLISIS DEL DATASET DE EVALUACI√ìN:\n",
      "üìä Total de registros: 102684\n",
      "üö® Casos de fraude: 2813 (2.74%)\n",
      "‚úÖ Casos normales: 99871 (97.26%)\n",
      "üåç Pa√≠ses √∫nicos: 183\n",
      "üìû L√≠neas √∫nicas: 71752\n",
      "\n",
      "üìä ESTAD√çSTICAS POR CLASE:\n",
      "CASOS NORMALES (FRAUDE = 0):\n",
      "  üìû Llamadas - Min: 0, Max: 200, Media: 1.5\n",
      "  ‚è±Ô∏è Minutos - Min: 0.02, Max: 854.79, Media: 3.5\n",
      "  üéØ Destinos - Min: 0, Max: 121, Media: 1.2\n",
      "\n",
      "CASOS DE FRAUDE (FRAUDE = 1):\n",
      "  üìû Llamadas - Min: 1, Max: 295, Media: 57.3\n",
      "  ‚è±Ô∏è Minutos - Min: 0.02, Max: 459.02, Media: 82.7\n",
      "  üéØ Destinos - Min: 1, Max: 293, Media: 55.5\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüìÇ Cargando dataset de evaluaci√≥n...\")\n",
    "\n",
    "# Verificar que el archivo existe\n",
    "if not os.path.exists(EVALUATION_CSV_PATH):\n",
    "    print(f\"‚ùå Error: Archivo de evaluaci√≥n no encontrado: {EVALUATION_CSV_PATH}\")\n",
    "    print(f\"üìù Por favor, aseg√∫rate de que el archivo exista y contenga las columnas:\")\n",
    "    print(f\"   - FECHA, CODIGODEPAIS, LINEA, N_LLAMADAS, N_MINUTOS, N_DESTINOS, FRAUDE\")\n",
    "    print(f\"   - FRAUDE debe ser 1 (fraudulento) o 0 (normal)\")\n",
    "    exit()\n",
    "\n",
    "# Cargar dataset\n",
    "df_evaluacion = pd.read_csv(EVALUATION_CSV_PATH)\n",
    "\n",
    "# Convertir fecha a datetime si existe\n",
    "if 'FECHA' in df_evaluacion.columns:\n",
    "    df_evaluacion['FECHA'] = pd.to_datetime(df_evaluacion['FECHA'], format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "print(f\"‚úÖ Dataset cargado - Shape: {df_evaluacion.shape}\")\n",
    "\n",
    "# Verificar columnas requeridas\n",
    "columnas_requeridas = ['CODIGODEPAIS', 'LINEA', 'N_LLAMADAS', 'N_MINUTOS', 'N_DESTINOS', 'FRAUDE']\n",
    "columnas_faltantes = [col for col in columnas_requeridas if col not in df_evaluacion.columns]\n",
    "\n",
    "if columnas_faltantes:\n",
    "    print(f\"‚ùå Error: Columnas faltantes: {columnas_faltantes}\")\n",
    "    print(f\"üìã Columnas disponibles: {list(df_evaluacion.columns)}\")\n",
    "    exit()\n",
    "\n",
    "# Verificar valores de FRAUDE\n",
    "valores_fraude = df_evaluacion['FRAUDE'].unique()\n",
    "if not all(v in [0, 1] for v in valores_fraude):\n",
    "    print(f\"‚ùå Error: FRAUDE debe contener solo valores 0 o 1. Valores encontrados: {valores_fraude}\")\n",
    "    exit()\n",
    "\n",
    "print(f\"üîç AN√ÅLISIS DEL DATASET DE EVALUACI√ìN:\")\n",
    "print(f\"üìä Total de registros: {len(df_evaluacion)}\")\n",
    "print(f\"üö® Casos de fraude: {df_evaluacion['FRAUDE'].sum()} ({df_evaluacion['FRAUDE'].mean()*100:.2f}%)\")\n",
    "print(f\"‚úÖ Casos normales: {(df_evaluacion['FRAUDE'] == 0).sum()} ({(df_evaluacion['FRAUDE'] == 0).mean()*100:.2f}%)\")\n",
    "print(f\"üåç Pa√≠ses √∫nicos: {df_evaluacion['CODIGODEPAIS'].nunique()}\")\n",
    "print(f\"üìû L√≠neas √∫nicas: {df_evaluacion['LINEA'].nunique()}\")\n",
    "\n",
    "# Mostrar estad√≠sticas por clase\n",
    "print(f\"\\nüìä ESTAD√çSTICAS POR CLASE:\")\n",
    "print(f\"CASOS NORMALES (FRAUDE = 0):\")\n",
    "normales = df_evaluacion[df_evaluacion['FRAUDE'] == 0]\n",
    "print(f\"  üìû Llamadas - Min: {normales['N_LLAMADAS'].min()}, Max: {normales['N_LLAMADAS'].max()}, Media: {normales['N_LLAMADAS'].mean():.1f}\")\n",
    "print(f\"  ‚è±Ô∏è Minutos - Min: {normales['N_MINUTOS'].min()}, Max: {normales['N_MINUTOS'].max()}, Media: {normales['N_MINUTOS'].mean():.1f}\")\n",
    "print(f\"  üéØ Destinos - Min: {normales['N_DESTINOS'].min()}, Max: {normales['N_DESTINOS'].max()}, Media: {normales['N_DESTINOS'].mean():.1f}\")\n",
    "\n",
    "if df_evaluacion['FRAUDE'].sum() > 0:\n",
    "    print(f\"\\nCASOS DE FRAUDE (FRAUDE = 1):\")\n",
    "    fraudes = df_evaluacion[df_evaluacion['FRAUDE'] == 1]\n",
    "    print(f\"  üìû Llamadas - Min: {fraudes['N_LLAMADAS'].min()}, Max: {fraudes['N_LLAMADAS'].max()}, Media: {fraudes['N_LLAMADAS'].mean():.1f}\")\n",
    "    print(f\"  ‚è±Ô∏è Minutos - Min: {fraudes['N_MINUTOS'].min()}, Max: {fraudes['N_MINUTOS'].max()}, Media: {fraudes['N_MINUTOS'].mean():.1f}\")\n",
    "    print(f\"  üéØ Destinos - Min: {fraudes['N_DESTINOS'].min()}, Max: {fraudes['N_DESTINOS'].max()}, Media: {fraudes['N_DESTINOS'].mean():.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ece1bd",
   "metadata": {},
   "source": [
    "# # 20. REALIZAR PREDICCIONES EN DATASET DE EVALUACI√ìN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "565f08d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÆ Realizando predicciones en dataset de evaluaci√≥n...\n",
      "   Procesando: 0/102684 registros\n",
      "   Procesando: 1000/102684 registros\n",
      "   Procesando: 2000/102684 registros\n",
      "   Procesando: 3000/102684 registros\n",
      "   Procesando: 4000/102684 registros\n",
      "   Procesando: 5000/102684 registros\n",
      "   Procesando: 6000/102684 registros\n",
      "   Procesando: 7000/102684 registros\n",
      "   Procesando: 8000/102684 registros\n",
      "   Procesando: 9000/102684 registros\n",
      "   Procesando: 10000/102684 registros\n",
      "   Procesando: 11000/102684 registros\n",
      "   Procesando: 12000/102684 registros\n",
      "   Procesando: 13000/102684 registros\n",
      "   Procesando: 14000/102684 registros\n",
      "   Procesando: 15000/102684 registros\n",
      "   Procesando: 16000/102684 registros\n",
      "   Procesando: 17000/102684 registros\n",
      "   Procesando: 18000/102684 registros\n",
      "   Procesando: 19000/102684 registros\n",
      "   Procesando: 20000/102684 registros\n",
      "   Procesando: 21000/102684 registros\n",
      "   Procesando: 22000/102684 registros\n",
      "   Procesando: 23000/102684 registros\n",
      "   Procesando: 24000/102684 registros\n",
      "   Procesando: 25000/102684 registros\n",
      "   Procesando: 26000/102684 registros\n",
      "   Procesando: 27000/102684 registros\n",
      "   Procesando: 28000/102684 registros\n",
      "   Procesando: 29000/102684 registros\n",
      "   Procesando: 30000/102684 registros\n",
      "   Procesando: 31000/102684 registros\n",
      "   Procesando: 32000/102684 registros\n",
      "   Procesando: 33000/102684 registros\n",
      "   Procesando: 34000/102684 registros\n",
      "   Procesando: 35000/102684 registros\n",
      "   Procesando: 36000/102684 registros\n",
      "   Procesando: 37000/102684 registros\n",
      "   Procesando: 38000/102684 registros\n",
      "   Procesando: 39000/102684 registros\n",
      "   Procesando: 40000/102684 registros\n",
      "   Procesando: 41000/102684 registros\n",
      "   Procesando: 42000/102684 registros\n",
      "   Procesando: 43000/102684 registros\n",
      "   Procesando: 44000/102684 registros\n",
      "   Procesando: 45000/102684 registros\n",
      "   Procesando: 46000/102684 registros\n",
      "   Procesando: 47000/102684 registros\n",
      "   Procesando: 48000/102684 registros\n",
      "   Procesando: 49000/102684 registros\n",
      "   Procesando: 50000/102684 registros\n",
      "   Procesando: 51000/102684 registros\n",
      "   Procesando: 52000/102684 registros\n",
      "   Procesando: 53000/102684 registros\n",
      "   Procesando: 54000/102684 registros\n",
      "   Procesando: 55000/102684 registros\n",
      "   Procesando: 56000/102684 registros\n",
      "   Procesando: 57000/102684 registros\n",
      "   Procesando: 58000/102684 registros\n",
      "   Procesando: 59000/102684 registros\n",
      "   Procesando: 60000/102684 registros\n",
      "   Procesando: 61000/102684 registros\n",
      "   Procesando: 62000/102684 registros\n",
      "   Procesando: 63000/102684 registros\n",
      "   Procesando: 64000/102684 registros\n",
      "   Procesando: 65000/102684 registros\n",
      "   Procesando: 66000/102684 registros\n",
      "   Procesando: 67000/102684 registros\n",
      "   Procesando: 68000/102684 registros\n",
      "   Procesando: 69000/102684 registros\n",
      "   Procesando: 70000/102684 registros\n",
      "   Procesando: 71000/102684 registros\n",
      "   Procesando: 72000/102684 registros\n",
      "   Procesando: 73000/102684 registros\n",
      "   Procesando: 74000/102684 registros\n",
      "   Procesando: 75000/102684 registros\n",
      "   Procesando: 76000/102684 registros\n",
      "   Procesando: 77000/102684 registros\n",
      "   Procesando: 78000/102684 registros\n",
      "   Procesando: 79000/102684 registros\n",
      "   Procesando: 80000/102684 registros\n",
      "   Procesando: 81000/102684 registros\n",
      "   Procesando: 82000/102684 registros\n",
      "   Procesando: 83000/102684 registros\n",
      "   Procesando: 84000/102684 registros\n",
      "   Procesando: 85000/102684 registros\n",
      "   Procesando: 86000/102684 registros\n",
      "   Procesando: 87000/102684 registros\n",
      "   Procesando: 88000/102684 registros\n",
      "   Procesando: 89000/102684 registros\n",
      "   Procesando: 90000/102684 registros\n",
      "   Procesando: 91000/102684 registros\n",
      "   Procesando: 92000/102684 registros\n",
      "   Procesando: 93000/102684 registros\n",
      "   Procesando: 94000/102684 registros\n",
      "   Procesando: 95000/102684 registros\n",
      "   Procesando: 96000/102684 registros\n",
      "   Procesando: 97000/102684 registros\n",
      "   Procesando: 98000/102684 registros\n",
      "   Procesando: 99000/102684 registros\n",
      "   Procesando: 100000/102684 registros\n",
      "   Procesando: 101000/102684 registros\n",
      "   Procesando: 102000/102684 registros\n",
      "‚úÖ Predicciones completadas\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüîÆ Realizando predicciones en dataset de evaluaci√≥n...\")\n",
    "\n",
    "predicciones = []\n",
    "scores = []\n",
    "\n",
    "for contador, (idx, row) in enumerate(df_evaluacion.iterrows()):\n",
    "    if contador % 1000 == 0:\n",
    "        print(f\"   Procesando: {contador}/{len(df_evaluacion)} registros\")\n",
    "    \n",
    "    # Realizar predicci√≥n\n",
    "    resultado = predecir_anomalia_mejorada(\n",
    "        pais=row['CODIGODEPAIS'],\n",
    "        linea=row['LINEA'],\n",
    "        llamadas=row['N_LLAMADAS'],\n",
    "        minutos=row['N_MINUTOS'],\n",
    "        destinos=row['N_DESTINOS'],\n",
    "        modelo=modelo_cargado,\n",
    "        scaler=scaler_cargado,\n",
    "        umbral=umbral_global,\n",
    "        stats_dict=stats_por_pais_dict\n",
    "    )\n",
    "    \n",
    "    # Guardar predicci√≥n (1 si es anomal√≠a, 0 si es normal)\n",
    "    predicciones.append(1 if resultado['es_anomalia'] else 0)\n",
    "    scores.append(resultado['score'])\n",
    "\n",
    "# Agregar predicciones al dataframe\n",
    "df_evaluacion['PREDICCION'] = predicciones\n",
    "df_evaluacion['SCORE_ANOMALIA'] = scores\n",
    "\n",
    "print(f\"‚úÖ Predicciones completadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cbdeaa",
   "metadata": {},
   "source": [
    "# # 21. CALCULAR M√âTRICAS Y MATRIZ DE CONFUSI√ìN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b46d9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä CALCULANDO M√âTRICAS DE EVALUACI√ìN...\n",
      "üéØ M√âTRICAS DE EVALUACI√ìN:\n",
      "üìà Accuracy (Exactitud): 0.9911 (99.11%)\n",
      "üéØ Precision (Precisi√≥n): 0.8988 (89.88%)\n",
      "üîç Recall (Sensibilidad): 0.7611 (76.11%)\n",
      "‚öñÔ∏è F1-Score: 0.8243 (82.43%)\n",
      "\n",
      "üìã MATRIZ DE CONFUSI√ìN:\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ     REAL \\ PRED ‚îÇ   Normal   ‚îÇ Anomal√≠a ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ      Normal     ‚îÇ    99630   ‚îÇ     241  ‚îÇ\n",
      "‚îÇ     Fraude      ‚îÇ      672   ‚îÇ    2141  ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "\n",
      "üî¢ INTERPRETACI√ìN:\n",
      "‚úÖ Verdaderos Negativos (TN): 99630 - Casos normales correctamente identificados\n",
      "‚ùå Falsos Positivos (FP): 241 - Casos normales incorrectamente marcados como fraude\n",
      "‚ùå Falsos Negativos (FN): 672 - Casos de fraude no detectados\n",
      "‚úÖ Verdaderos Positivos (TP): 2141 - Casos de fraude correctamente detectados\n",
      "üõ°Ô∏è Especificidad (Tasa de Verdaderos Negativos): 0.9976 (99.76%)\n",
      "‚ö†Ô∏è Tasa de Falsos Positivos: 0.0024 (0.24%)\n",
      "‚ö†Ô∏è Tasa de Falsos Negativos: 0.2389 (23.89%)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüìä CALCULANDO M√âTRICAS DE EVALUACI√ìN...\")\n",
    "\n",
    "# Extraer etiquetas reales y predicciones\n",
    "y_true = df_evaluacion['FRAUDE'].values\n",
    "y_pred = df_evaluacion['PREDICCION'].values\n",
    "\n",
    "# Calcular m√©tricas principales\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"üéØ M√âTRICAS DE EVALUACI√ìN:\")\n",
    "print(f\"üìà Accuracy (Exactitud): {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"üéØ Precision (Precisi√≥n): {precision:.4f} ({precision*100:.2f}%)\")\n",
    "print(f\"üîç Recall (Sensibilidad): {recall:.4f} ({recall*100:.2f}%)\")\n",
    "print(f\"‚öñÔ∏è F1-Score: {f1:.4f} ({f1*100:.2f}%)\")\n",
    "\n",
    "# Calcular matriz de confusi√≥n\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f\"\\nüìã MATRIZ DE CONFUSI√ìN:\")\n",
    "print(f\"‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\")\n",
    "print(f\"‚îÇ     REAL \\\\ PRED ‚îÇ   Normal   ‚îÇ Anomal√≠a ‚îÇ\")\n",
    "print(f\"‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\")\n",
    "print(f\"‚îÇ      Normal     ‚îÇ   {tn:6d}   ‚îÇ  {fp:6d}  ‚îÇ\")\n",
    "print(f\"‚îÇ     Fraude      ‚îÇ   {fn:6d}   ‚îÇ  {tp:6d}  ‚îÇ\")\n",
    "print(f\"‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")\n",
    "\n",
    "print(f\"\\nüî¢ INTERPRETACI√ìN:\")\n",
    "print(f\"‚úÖ Verdaderos Negativos (TN): {tn} - Casos normales correctamente identificados\")\n",
    "print(f\"‚ùå Falsos Positivos (FP): {fp} - Casos normales incorrectamente marcados como fraude\")\n",
    "print(f\"‚ùå Falsos Negativos (FN): {fn} - Casos de fraude no detectados\")\n",
    "print(f\"‚úÖ Verdaderos Positivos (TP): {tp} - Casos de fraude correctamente detectados\")\n",
    "\n",
    "# Calcular tasas adicionales\n",
    "if (tn + fp) > 0:\n",
    "    especificidad = tn / (tn + fp)\n",
    "    print(f\"üõ°Ô∏è Especificidad (Tasa de Verdaderos Negativos): {especificidad:.4f} ({especificidad*100:.2f}%)\")\n",
    "\n",
    "if (fp + tn) > 0:\n",
    "    tasa_fp = fp / (fp + tn)\n",
    "    print(f\"‚ö†Ô∏è Tasa de Falsos Positivos: {tasa_fp:.4f} ({tasa_fp*100:.2f}%)\")\n",
    "\n",
    "if (fn + tp) > 0:\n",
    "    tasa_fn = fn / (fn + tp)\n",
    "    print(f\"‚ö†Ô∏è Tasa de Falsos Negativos: {tasa_fn:.4f} ({tasa_fn*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40730587",
   "metadata": {},
   "source": [
    "# # 22. Guardar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1528d195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Resultados completos: C:\\Users\\User\\Desktop\\TESIS\\Modelos\\resultados_evaluacion_completa.csv\n"
     ]
    }
   ],
   "source": [
    "resultados_path = os.path.join(MODELS_PATH, \"resultados_evaluacion_completa.csv\")\n",
    "df_evaluacion.to_csv(resultados_path, index=False)\n",
    "print(f\"üìÑ Resultados completos: {resultados_path}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
